{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-12 00:39:11.358926: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-12 00:39:11.531533: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-12 00:39:12.248667: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-12 00:39:12.248759: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-12 00:39:12.248770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import torch\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "from transformers import RealmRetriever, RealmTokenizerFast, RealmForOpenQA, RealmConfig\n",
    "\n",
    "from transformers.models.realm.retrieval_realm import convert_tfrecord_to_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_infos\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikipedia/20220301.en to /home/patrick/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5358f394e75415ba0cdb10eadc2e48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/15.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab748133531d4f8ba1004ce836bcc464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/20.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikipedia downloaded and prepared to /home/patrick/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5926023b75554ef596fc18ec4785565d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wiki_data = load_dataset(\"wikipedia\", \"20220301.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "wiki_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filter:                  id         revid\n",
      "count     73.000000  7.300000e+01\n",
      "mean   32669.767123  1.282680e+08\n",
      "std       30.284540  3.286560e+08\n",
      "min    32616.000000  3.200500e+04\n",
      "25%    32645.000000  3.461395e+06\n",
      "50%    32672.000000  9.784415e+06\n",
      "75%    32695.000000  3.533295e+07\n",
      "max    32720.000000  1.060874e+09\n",
      "After filter:                  id         revid\n",
      "count     61.000000  6.100000e+01\n",
      "mean   32669.737705  1.527047e+08\n",
      "std       30.090365  3.548528e+08\n",
      "min    32616.000000  3.200500e+04\n",
      "25%    32644.000000  5.280263e+06\n",
      "50%    32673.000000  1.241690e+07\n",
      "75%    32695.000000  3.962001e+07\n",
      "max    32718.000000  1.060874e+09\n"
     ]
    }
   ],
   "source": [
    "sample_docs = pd.read_json('data/wiki-raw/enwiki-20211220/AD/wiki_00', lines=True)\n",
    "print(f\"Before filter: {sample_docs.describe()}\")\n",
    "\n",
    "# we want to filter and keep only docs that have non-empty text fields.\n",
    "sample_docs = sample_docs[sample_docs['text'].str.len() > 0]\n",
    "sample_docs.describe()\n",
    "print(f\"After filter: {sample_docs.describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# We need to go from a dataframe to an array of text\n",
    "def get_documents(path: str) -> List[str]:\n",
    "    df = pd.read_json(path_or_buf=path, lines=True)\n",
    "\n",
    "    # check that it's read in\n",
    "    print(f\"Read in: {len(df)} lines from jsonl file: {path}\")\n",
    "    print(f\"Dataframe columns: {df.columns}\")\n",
    "\n",
    "    # filter rows with empty text\n",
    "    try:\n",
    "        df = df[df['text'].str.len() > 0]\n",
    "        print(f\"After filtering rows with empty text, df size: {len(df)}\")\n",
    "    except KeyError as ke:\n",
    "        return []\n",
    "\n",
    "    # return only the \"text\" column to be used with the retriever\n",
    "    return df.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# for each file in the directory, we need to pull its content\n",
    "def get_directory_contents(dir_name: str):\n",
    "    dir_data = list()\n",
    "    for sub_dir_name in os.listdir(dir_name):\n",
    "        files = os.listdir(os.path.join(dir_name + '/' + sub_dir_name))\n",
    "        for _file in files:\n",
    "            dir_data += get_documents(os.path.join(dir_name + '/' + sub_dir_name+'/' + _file))\n",
    "    return dir_data\n",
    "\n",
    "\n",
    "# return all evidence texts as a numpy ndarray\n",
    "def get_evidence_text():\n",
    "    return np.asarray(get_directory_contents(\"data/wiki-raw/sample-enwiki-20211220\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "evidence_texts = get_evidence_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# we need to save this an dopen it again, for memory saving purposes\n",
    "np.savetxt('data/wiki-raw/database/evidence_texts.txt', evidence_texts, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15832,)\n"
     ]
    }
   ],
   "source": [
    "print(evidence_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Read in sample database texts if they've already been processed\n",
    "evidence_texts = np.loadtxt('data/wiki-raw/database/evidence_texts.txt', dtype=str, delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852051,)\n"
     ]
    }
   ],
   "source": [
    "print(evidence_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Is it possible to initialize a realm retriever with a block of texts?\n",
    "\n",
    "# 1. Let's find some texts\n",
    "evidence_texts = np.asarray(sample_docs.text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 2. Retriever from sample evidence texts\n",
    "tokenizer = RealmTokenizerFast.from_pretrained(\"google/realm-cc-news-pretrained-encoder\")\n",
    "\n",
    "retriever = RealmRetriever(evidence_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/realm-cc-news-pretrained-encoder were not used when initializing RealmForOpenQA: ['realm.encoder.layer.1.attention.output.dense.bias', 'realm.encoder.layer.5.attention.output.dense.weight', 'realm.encoder.layer.7.attention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'realm.encoder.layer.0.attention.self.key.bias', 'realm.encoder.layer.8.attention.self.value.weight', 'realm.encoder.layer.10.attention.self.value.weight', 'realm.encoder.layer.0.attention.output.dense.weight', 'cls.predictions.bias', 'realm.encoder.layer.0.attention.self.value.bias', 'realm.encoder.layer.6.attention.self.value.weight', 'realm.encoder.layer.6.attention.self.value.bias', 'realm.encoder.layer.0.output.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'realm.encoder.layer.6.attention.self.key.weight', 'realm.embeddings.LayerNorm.weight', 'realm.encoder.layer.9.attention.self.key.bias', 'realm.encoder.layer.10.intermediate.dense.weight', 'realm.encoder.layer.5.attention.output.dense.bias', 'realm.encoder.layer.8.output.dense.weight', 'realm.encoder.layer.5.attention.self.value.bias', 'realm.encoder.layer.2.output.dense.bias', 'realm.encoder.layer.8.attention.output.LayerNorm.bias', 'realm.encoder.layer.7.intermediate.dense.weight', 'realm.encoder.layer.0.attention.self.value.weight', 'realm.encoder.layer.9.attention.self.query.weight', 'realm.embeddings.position_ids', 'realm.encoder.layer.3.attention.self.value.weight', 'realm.pooler.dense.bias', 'realm.encoder.layer.8.attention.self.value.bias', 'realm.encoder.layer.7.output.LayerNorm.bias', 'realm.encoder.layer.9.attention.self.value.weight', 'realm.encoder.layer.3.attention.output.dense.weight', 'realm.encoder.layer.11.attention.output.dense.weight', 'realm.encoder.layer.6.output.dense.bias', 'realm.encoder.layer.7.attention.self.key.weight', 'realm.encoder.layer.11.attention.output.LayerNorm.weight', 'realm.encoder.layer.5.attention.self.value.weight', 'realm.encoder.layer.11.output.dense.bias', 'realm.encoder.layer.9.attention.self.query.bias', 'realm.encoder.layer.4.attention.output.dense.bias', 'realm.encoder.layer.9.attention.self.value.bias', 'realm.encoder.layer.10.attention.output.dense.weight', 'realm.encoder.layer.11.attention.self.query.bias', 'realm.encoder.layer.4.attention.self.query.weight', 'realm.encoder.layer.6.intermediate.dense.weight', 'realm.encoder.layer.7.attention.self.query.bias', 'realm.encoder.layer.4.attention.self.key.weight', 'realm.encoder.layer.9.output.LayerNorm.weight', 'realm.encoder.layer.2.attention.self.key.bias', 'realm.encoder.layer.10.output.dense.weight', 'realm.encoder.layer.8.attention.output.dense.weight', 'realm.encoder.layer.0.output.LayerNorm.weight', 'realm.encoder.layer.1.attention.self.key.bias', 'realm.encoder.layer.1.attention.output.LayerNorm.weight', 'realm.encoder.layer.7.attention.self.key.bias', 'realm.encoder.layer.0.intermediate.dense.bias', 'realm.encoder.layer.5.intermediate.dense.bias', 'realm.encoder.layer.7.attention.self.query.weight', 'realm.encoder.layer.8.attention.output.LayerNorm.weight', 'realm.embeddings.position_embeddings.weight', 'realm.encoder.layer.6.attention.self.query.bias', 'realm.encoder.layer.1.attention.self.query.weight', 'realm.encoder.layer.11.attention.self.key.weight', 'realm.encoder.layer.7.attention.self.value.bias', 'realm.encoder.layer.5.attention.self.key.weight', 'realm.encoder.layer.6.intermediate.dense.bias', 'realm.encoder.layer.8.output.dense.bias', 'realm.encoder.layer.10.intermediate.dense.bias', 'realm.encoder.layer.1.intermediate.dense.bias', 'realm.encoder.layer.2.attention.self.value.bias', 'realm.encoder.layer.11.output.LayerNorm.bias', 'realm.encoder.layer.4.attention.self.value.bias', 'realm.encoder.layer.6.attention.output.LayerNorm.weight', 'realm.encoder.layer.3.attention.self.query.bias', 'realm.encoder.layer.9.attention.output.dense.bias', 'realm.encoder.layer.3.intermediate.dense.bias', 'realm.encoder.layer.4.attention.self.value.weight', 'realm.encoder.layer.11.attention.self.key.bias', 'realm.encoder.layer.3.attention.output.dense.bias', 'realm.encoder.layer.4.intermediate.dense.bias', 'realm.encoder.layer.9.intermediate.dense.weight', 'realm.encoder.layer.2.attention.output.LayerNorm.bias', 'realm.encoder.layer.2.output.LayerNorm.bias', 'realm.encoder.layer.4.output.dense.bias', 'realm.encoder.layer.11.attention.self.value.weight', 'realm.encoder.layer.3.attention.self.value.bias', 'realm.encoder.layer.7.attention.output.LayerNorm.weight', 'realm.encoder.layer.10.output.dense.bias', 'realm.encoder.layer.5.output.dense.bias', 'realm.encoder.layer.8.attention.self.key.weight', 'realm.encoder.layer.11.output.dense.weight', 'realm.encoder.layer.0.attention.output.dense.bias', 'realm.encoder.layer.2.output.LayerNorm.weight', 'realm.encoder.layer.6.attention.output.LayerNorm.bias', 'realm.encoder.layer.10.attention.self.query.weight', 'realm.encoder.layer.4.attention.self.query.bias', 'realm.encoder.layer.2.attention.self.query.weight', 'realm.encoder.layer.2.attention.self.query.bias', 'realm.encoder.layer.4.output.LayerNorm.bias', 'realm.encoder.layer.9.attention.output.LayerNorm.weight', 'realm.embeddings.LayerNorm.bias', 'realm.encoder.layer.5.attention.self.query.bias', 'realm.encoder.layer.3.output.LayerNorm.bias', 'realm.encoder.layer.11.attention.output.dense.bias', 'realm.encoder.layer.7.attention.output.dense.bias', 'realm.encoder.layer.10.attention.output.LayerNorm.weight', 'realm.encoder.layer.9.output.LayerNorm.bias', 'realm.encoder.layer.3.intermediate.dense.weight', 'realm.encoder.layer.5.output.LayerNorm.bias', 'realm.encoder.layer.0.output.LayerNorm.bias', 'realm.encoder.layer.1.output.LayerNorm.weight', 'realm.encoder.layer.2.attention.self.key.weight', 'realm.encoder.layer.5.output.dense.weight', 'realm.encoder.layer.6.output.dense.weight', 'realm.encoder.layer.10.attention.output.dense.bias', 'realm.encoder.layer.11.intermediate.dense.bias', 'realm.encoder.layer.8.output.LayerNorm.weight', 'realm.encoder.layer.3.output.LayerNorm.weight', 'realm.encoder.layer.6.attention.self.key.bias', 'realm.encoder.layer.4.attention.output.LayerNorm.bias', 'realm.encoder.layer.4.output.LayerNorm.weight', 'realm.encoder.layer.6.output.LayerNorm.weight', 'realm.encoder.layer.1.attention.output.LayerNorm.bias', 'realm.encoder.layer.4.attention.output.LayerNorm.weight', 'realm.encoder.layer.11.output.LayerNorm.weight', 'realm.encoder.layer.3.attention.output.LayerNorm.bias', 'realm.encoder.layer.7.output.dense.bias', 'realm.encoder.layer.0.attention.self.key.weight', 'realm.encoder.layer.5.attention.output.LayerNorm.weight', 'realm.encoder.layer.5.attention.output.LayerNorm.bias', 'realm.encoder.layer.11.attention.output.LayerNorm.bias', 'realm.encoder.layer.9.intermediate.dense.bias', 'realm.encoder.layer.1.attention.self.value.weight', 'realm.encoder.layer.0.attention.output.LayerNorm.bias', 'realm.encoder.layer.0.output.dense.bias', 'realm.encoder.layer.2.output.dense.weight', 'realm.encoder.layer.8.attention.self.key.bias', 'realm.encoder.layer.6.output.LayerNorm.bias', 'realm.encoder.layer.1.attention.self.value.bias', 'realm.encoder.layer.10.output.LayerNorm.weight', 'realm.encoder.layer.1.output.dense.weight', 'realm.encoder.layer.2.intermediate.dense.bias', 'realm.encoder.layer.3.attention.output.LayerNorm.weight', 'realm.embeddings.token_type_embeddings.weight', 'realm.encoder.layer.5.attention.self.query.weight', 'realm.encoder.layer.9.output.dense.weight', 'realm.encoder.layer.2.attention.self.value.weight', 'realm.encoder.layer.3.attention.self.query.weight', 'realm.encoder.layer.4.attention.output.dense.weight', 'realm.encoder.layer.1.attention.self.key.weight', 'realm.encoder.layer.3.attention.self.key.weight', 'realm.encoder.layer.4.output.dense.weight', 'realm.encoder.layer.5.attention.self.key.bias', 'realm.encoder.layer.1.output.LayerNorm.bias', 'realm.embeddings.word_embeddings.weight', 'realm.encoder.layer.3.output.dense.weight', 'realm.encoder.layer.1.intermediate.dense.weight', 'realm.encoder.layer.9.attention.output.dense.weight', 'realm.encoder.layer.2.attention.output.dense.bias', 'realm.encoder.layer.4.attention.self.key.bias', 'realm.encoder.layer.0.attention.self.query.weight', 'realm.encoder.layer.10.attention.self.query.bias', 'realm.encoder.layer.10.attention.self.key.bias', 'realm.encoder.layer.11.attention.self.query.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'realm.encoder.layer.1.attention.output.dense.weight', 'realm.encoder.layer.9.output.dense.bias', 'realm.encoder.layer.2.intermediate.dense.weight', 'realm.encoder.layer.6.attention.self.query.weight', 'realm.encoder.layer.8.intermediate.dense.bias', 'realm.encoder.layer.0.intermediate.dense.weight', 'realm.encoder.layer.10.attention.self.key.weight', 'realm.encoder.layer.5.intermediate.dense.weight', 'realm.encoder.layer.10.output.LayerNorm.bias', 'realm.encoder.layer.0.attention.self.query.bias', 'realm.encoder.layer.6.attention.output.dense.bias', 'realm.encoder.layer.1.attention.self.query.bias', 'realm.encoder.layer.3.attention.self.key.bias', 'realm.encoder.layer.9.attention.output.LayerNorm.bias', 'realm.encoder.layer.7.output.LayerNorm.weight', 'realm.encoder.layer.7.attention.output.dense.weight', 'realm.encoder.layer.8.attention.self.query.weight', 'realm.encoder.layer.8.attention.output.dense.bias', 'realm.encoder.layer.10.attention.output.LayerNorm.bias', 'realm.encoder.layer.5.output.LayerNorm.weight', 'realm.encoder.layer.1.output.dense.bias', 'cls.predictions.transform.dense.weight', 'realm.encoder.layer.7.output.dense.weight', 'realm.encoder.layer.7.attention.self.value.weight', 'realm.encoder.layer.8.intermediate.dense.weight', 'realm.encoder.layer.2.attention.output.LayerNorm.weight', 'realm.pooler.dense.weight', 'realm.encoder.layer.2.attention.output.dense.weight', 'cls.predictions.transform.dense.bias', 'realm.encoder.layer.9.attention.self.key.weight', 'realm.encoder.layer.7.intermediate.dense.bias', 'realm.encoder.layer.6.attention.output.dense.weight', 'realm.encoder.layer.8.attention.self.query.bias', 'realm.encoder.layer.4.intermediate.dense.weight', 'realm.encoder.layer.11.intermediate.dense.weight', 'realm.encoder.layer.0.attention.output.LayerNorm.weight', 'realm.encoder.layer.3.output.dense.bias', 'realm.encoder.layer.10.attention.self.value.bias', 'realm.encoder.layer.8.output.LayerNorm.bias', 'realm.encoder.layer.11.attention.self.value.bias']\n",
      "- This IS expected if you are initializing RealmForOpenQA from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RealmForOpenQA from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RealmForOpenQA were not initialized from the model checkpoint at google/realm-cc-news-pretrained-encoder and are newly initialized: ['realm.reader.realm.encoder.layer.7.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.8.attention.self.key.bias', 'realm.embedder.realm.encoder.layer.5.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.5.attention.self.key.bias', 'realm.embedder.realm.encoder.layer.5.attention.output.LayerNorm.weight', 'realm.reader.realm.pooler.dense.weight', 'realm.reader.cls.predictions.transform.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.4.output.LayerNorm.weight', 'realm.embedder.cls.predictions.transform.dense.weight', 'realm.embedder.realm.encoder.layer.6.attention.self.value.weight', 'realm.reader.realm.encoder.layer.3.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.8.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.3.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.5.attention.self.key.weight', 'realm.embedder.realm.encoder.layer.0.attention.output.dense.bias', 'realm.embedder.realm.encoder.layer.0.attention.output.dense.weight', 'realm.reader.realm.encoder.layer.2.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.6.attention.output.dense.weight', 'realm.reader.realm.encoder.layer.11.attention.self.key.weight', 'realm.reader.realm.encoder.layer.9.attention.self.query.bias', 'realm.reader.realm.encoder.layer.7.attention.self.key.bias', 'realm.reader.realm.encoder.layer.8.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.11.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.1.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.3.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.4.attention.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.2.attention.self.key.weight', 'realm.embedder.realm.encoder.layer.8.attention.self.key.weight', 'realm.embedder.realm.encoder.layer.1.output.dense.bias', 'realm.embedder.realm.encoder.layer.11.output.dense.weight', 'realm.embedder.realm.encoder.layer.0.attention.self.key.weight', 'realm.embedder.realm.encoder.layer.10.attention.self.key.bias', 'realm.reader.realm.encoder.layer.11.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.3.output.dense.bias', 'realm.reader.realm.encoder.layer.6.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.10.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.10.attention.output.dense.weight', 'realm.reader.realm.encoder.layer.6.output.dense.weight', 'realm.embedder.realm.encoder.layer.3.attention.self.key.weight', 'realm.embedder.realm.encoder.layer.6.attention.self.key.bias', 'realm.embedder.realm.encoder.layer.6.output.dense.weight', 'realm.reader.realm.encoder.layer.7.attention.self.query.weight', 'realm.embedder.realm.encoder.layer.3.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.0.output.dense.weight', 'realm.embedder.realm.encoder.layer.6.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.1.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.2.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.0.attention.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.8.intermediate.dense.weight', 'realm.reader.cls.predictions.decoder.weight', 'realm.embedder.realm.encoder.layer.0.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.4.attention.self.key.bias', 'realm.embedder.realm.encoder.layer.10.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.0.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.10.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.3.attention.self.key.bias', 'realm.embedder.realm.encoder.layer.1.output.dense.weight', 'realm.embedder.realm.encoder.layer.4.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.0.attention.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.10.output.dense.bias', 'realm.embedder.realm.encoder.layer.9.attention.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.2.attention.self.value.bias', 'realm.reader.realm.encoder.layer.6.attention.self.query.weight', 'realm.reader.realm.encoder.layer.1.output.dense.weight', 'realm.reader.realm.encoder.layer.9.attention.output.dense.weight', 'realm.reader.realm.encoder.layer.0.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.2.intermediate.dense.bias', 'realm.embedder.realm.encoder.layer.7.attention.self.value.bias', 'realm.reader.realm.encoder.layer.0.attention.output.dense.weight', 'realm.reader.realm.encoder.layer.1.attention.self.query.bias', 'realm.embedder.realm.pooler.dense.bias', 'realm.embedder.realm.encoder.layer.10.attention.self.key.weight', 'realm.reader.realm.encoder.layer.7.attention.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.10.attention.self.key.weight', 'realm.embedder.cls.predictions.transform.LayerNorm.weight', 'realm.reader.realm.encoder.layer.1.attention.self.key.weight', 'realm.reader.qa_outputs.dense_output.bias', 'realm.reader.realm.encoder.layer.3.attention.self.key.bias', 'realm.embedder.realm.encoder.layer.10.output.dense.weight', 'realm.embedder.realm.embeddings.position_embeddings.weight', 'realm.reader.realm.encoder.layer.9.output.dense.bias', 'realm.reader.realm.encoder.layer.1.attention.self.key.bias', 'realm.reader.realm.encoder.layer.3.intermediate.dense.weight', 'realm.embedder.realm.encoder.layer.7.attention.self.key.weight', 'realm.reader.realm.encoder.layer.0.attention.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.2.output.dense.weight', 'realm.reader.realm.encoder.layer.1.attention.self.query.weight', 'realm.reader.realm.encoder.layer.2.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.7.output.dense.weight', 'realm.embedder.cls.LayerNorm.bias', 'realm.reader.realm.encoder.layer.9.attention.self.key.bias', 'realm.reader.realm.encoder.layer.7.output.dense.bias', 'realm.embedder.realm.encoder.layer.11.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.9.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.3.attention.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.4.attention.self.query.weight', 'realm.reader.realm.encoder.layer.4.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.2.attention.output.dense.weight', 'realm.reader.realm.encoder.layer.11.output.dense.weight', 'realm.reader.realm.encoder.layer.8.attention.self.value.weight', 'realm.embedder.cls.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.11.attention.self.query.weight', 'realm.reader.realm.encoder.layer.0.intermediate.dense.bias', 'realm.embedder.realm.encoder.layer.2.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.9.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.10.attention.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.3.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.9.attention.self.key.bias', 'realm.reader.realm.encoder.layer.5.attention.self.query.bias', 'realm.reader.realm.encoder.layer.0.attention.self.key.weight', 'realm.reader.realm.encoder.layer.6.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.3.attention.output.dense.weight', 'realm.reader.cls.predictions.transform.dense.bias', 'realm.embedder.realm.encoder.layer.4.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.6.attention.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.11.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.6.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.11.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.4.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.5.attention.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.11.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.2.attention.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.4.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.8.attention.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.2.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.1.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.7.attention.self.query.bias', 'realm.reader.realm.embeddings.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.10.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.2.attention.output.LayerNorm.bias', 'realm.embedder.cls.predictions.decoder.bias', 'realm.reader.realm.encoder.layer.4.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.9.attention.output.dense.bias', 'realm.embedder.realm.encoder.layer.3.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.3.output.dense.weight', 'realm.embedder.realm.encoder.layer.10.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.7.attention.output.dense.weight', 'realm.reader.qa_outputs.dense_intermediate.bias', 'realm.embedder.realm.encoder.layer.8.attention.output.LayerNorm.bias', 'realm.embedder.realm.pooler.dense.weight', 'realm.reader.realm.encoder.layer.0.attention.self.query.weight', 'realm.reader.realm.encoder.layer.1.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.2.attention.self.key.bias', 'realm.reader.realm.encoder.layer.0.output.dense.weight', 'realm.reader.realm.encoder.layer.6.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.0.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.5.attention.self.key.bias', 'realm.embedder.realm.encoder.layer.0.attention.self.value.weight', 'realm.reader.realm.encoder.layer.8.intermediate.dense.weight', 'realm.embedder.realm.encoder.layer.6.intermediate.dense.bias', 'realm.embedder.realm.encoder.layer.10.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.4.output.dense.weight', 'realm.reader.realm.encoder.layer.9.attention.self.query.weight', 'realm.reader.realm.encoder.layer.11.intermediate.dense.weight', 'realm.embedder.realm.encoder.layer.0.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.9.attention.self.query.weight', 'realm.reader.realm.encoder.layer.9.attention.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.2.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.6.attention.self.key.weight', 'realm.embedder.realm.encoder.layer.7.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.2.attention.self.key.weight', 'realm.reader.realm.encoder.layer.11.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.2.attention.self.query.bias', 'realm.reader.realm.encoder.layer.0.intermediate.dense.weight', 'realm.embedder.realm.encoder.layer.9.attention.self.value.bias', 'realm.reader.realm.encoder.layer.3.attention.self.query.weight', 'realm.reader.realm.encoder.layer.3.attention.output.dense.bias', 'realm.reader.realm.embeddings.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.9.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.3.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.4.output.dense.weight', 'realm.embedder.cls.predictions.transform.LayerNorm.bias', 'realm.reader.realm.encoder.layer.8.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.0.attention.self.key.bias', 'realm.embedder.realm.encoder.layer.10.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.2.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.6.attention.self.key.weight', 'realm.reader.realm.encoder.layer.9.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.7.output.dense.weight', 'realm.embedder.realm.encoder.layer.2.intermediate.dense.weight', 'realm.embedder.realm.encoder.layer.3.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.7.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.10.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.2.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.11.attention.self.query.bias', 'realm.reader.realm.encoder.layer.1.attention.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.3.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.3.output.dense.weight', 'realm.reader.realm.encoder.layer.7.intermediate.dense.weight', 'realm.embedder.realm.encoder.layer.5.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.4.attention.self.query.weight', 'realm.reader.realm.encoder.layer.10.attention.self.query.weight', 'realm.reader.realm.encoder.layer.11.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.5.intermediate.dense.bias', 'realm.embedder.realm.encoder.layer.6.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.3.attention.self.query.weight', 'realm.reader.realm.encoder.layer.9.attention.self.key.weight', 'realm.reader.realm.encoder.layer.1.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.7.intermediate.dense.weight', 'realm.embedder.realm.encoder.layer.4.output.dense.bias', 'realm.reader.realm.encoder.layer.11.attention.output.dense.bias', 'realm.reader.cls.predictions.transform.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.5.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.11.output.dense.bias', 'realm.reader.realm.encoder.layer.0.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.8.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.7.attention.self.query.weight', 'realm.reader.realm.encoder.layer.3.attention.self.key.weight', 'realm.embedder.realm.encoder.layer.1.attention.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.9.intermediate.dense.bias', 'realm.embedder.realm.encoder.layer.10.output.dense.bias', 'realm.reader.realm.encoder.layer.10.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.9.output.dense.weight', 'realm.embedder.realm.encoder.layer.2.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.1.attention.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.6.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.3.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.4.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.5.attention.self.value.bias', 'realm.reader.realm.encoder.layer.8.attention.self.key.weight', 'realm.reader.realm.encoder.layer.10.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.9.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.4.output.dense.bias', 'realm.reader.realm.encoder.layer.5.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.3.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.6.attention.output.dense.bias', 'realm.embedder.realm.encoder.layer.0.output.dense.bias', 'realm.embedder.realm.encoder.layer.3.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.7.attention.output.dense.bias', 'realm.embedder.realm.encoder.layer.11.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.0.attention.output.dense.bias', 'realm.embedder.realm.encoder.layer.2.output.dense.weight', 'realm.embedder.realm.encoder.layer.7.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.4.attention.self.key.weight', 'realm.embedder.realm.embeddings.word_embeddings.weight', 'realm.reader.realm.encoder.layer.2.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.1.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.1.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.8.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.4.attention.self.key.weight', 'realm.embedder.cls.predictions.transform.dense.bias', 'realm.reader.realm.encoder.layer.10.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.10.output.dense.weight', 'realm.reader.realm.encoder.layer.8.output.dense.bias', 'realm.embedder.realm.encoder.layer.8.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.11.attention.self.key.weight', 'realm.embedder.realm.encoder.layer.11.attention.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.8.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.7.attention.output.LayerNorm.bias', 'realm.reader.qa_outputs.layer_normalization.bias', 'realm.embedder.realm.encoder.layer.1.attention.self.query.bias', 'realm.embedder.realm.encoder.layer.5.output.dense.bias', 'realm.reader.realm.encoder.layer.5.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.10.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.10.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.7.attention.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.8.attention.self.query.weight', 'realm.reader.realm.encoder.layer.11.attention.self.query.bias', 'realm.reader.realm.encoder.layer.7.attention.self.value.bias', 'realm.reader.realm.encoder.layer.5.attention.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.1.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.6.intermediate.dense.weight', 'realm.embedder.realm.encoder.layer.10.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.7.intermediate.dense.bias', 'realm.embedder.realm.encoder.layer.0.attention.self.query.weight', 'realm.reader.realm.encoder.layer.2.attention.output.dense.bias', 'realm.embedder.realm.encoder.layer.9.output.LayerNorm.weight', 'realm.reader.cls.predictions.transform.dense.weight', 'realm.reader.realm.embeddings.token_type_embeddings.weight', 'realm.reader.realm.encoder.layer.10.attention.self.key.bias', 'realm.reader.realm.encoder.layer.7.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.7.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.9.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.4.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.1.attention.self.query.weight', 'realm.embedder.cls.dense.bias', 'realm.reader.realm.encoder.layer.4.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.3.output.dense.bias', 'realm.embedder.realm.encoder.layer.8.output.dense.weight', 'realm.embedder.realm.encoder.layer.1.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.11.attention.self.key.bias', 'realm.reader.realm.encoder.layer.6.attention.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.11.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.2.intermediate.dense.bias', 'realm.reader.realm.embeddings.position_embeddings.weight', 'realm.embedder.realm.encoder.layer.11.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.4.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.4.attention.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.8.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.4.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.10.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.6.attention.self.query.weight', 'realm.embedder.realm.encoder.layer.8.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.9.output.LayerNorm.weight', 'realm.reader.qa_outputs.layer_normalization.weight', 'realm.reader.realm.encoder.layer.5.attention.self.query.weight', 'realm.embedder.realm.encoder.layer.2.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.4.attention.output.dense.bias', 'realm.embedder.realm.encoder.layer.11.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.9.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.8.attention.self.query.weight', 'realm.embedder.realm.encoder.layer.10.attention.self.query.weight', 'realm.embedder.realm.encoder.layer.9.attention.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.11.intermediate.dense.bias', 'realm.embedder.realm.encoder.layer.3.attention.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.1.attention.self.key.bias', 'realm.reader.realm.encoder.layer.8.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.4.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.6.output.dense.bias', 'realm.reader.qa_outputs.dense_intermediate.weight', 'realm.reader.realm.encoder.layer.6.attention.self.value.bias', 'realm.reader.realm.encoder.layer.10.attention.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.8.output.dense.weight', 'realm.reader.realm.encoder.layer.8.intermediate.dense.bias', 'realm.reader.realm.pooler.dense.bias', 'realm.embedder.realm.encoder.layer.5.output.dense.weight', 'realm.reader.realm.encoder.layer.8.attention.self.query.bias', 'realm.reader.realm.encoder.layer.11.attention.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.9.attention.output.dense.bias', 'realm.embedder.cls.dense.weight', 'realm.reader.realm.encoder.layer.0.attention.self.query.bias', 'realm.embedder.realm.embeddings.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.1.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.0.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.4.attention.self.value.weight', 'realm.embedder.cls.predictions.decoder.weight', 'realm.reader.realm.encoder.layer.6.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.9.output.dense.weight', 'realm.embedder.cls.predictions.bias', 'realm.reader.realm.encoder.layer.3.output.LayerNorm.bias', 'realm.embedder.realm.embeddings.token_type_embeddings.weight', 'realm.reader.realm.encoder.layer.9.attention.output.LayerNorm.bias', 'realm.reader.qa_outputs.dense_output.weight', 'realm.embedder.realm.encoder.layer.5.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.6.attention.output.dense.weight', 'realm.reader.realm.encoder.layer.7.attention.self.query.bias', 'realm.reader.realm.encoder.layer.7.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.8.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.1.attention.self.key.weight', 'realm.reader.realm.encoder.layer.2.output.dense.bias', 'realm.embedder.realm.encoder.layer.3.attention.self.value.bias', 'realm.reader.realm.encoder.layer.8.attention.self.key.bias', 'realm.embedder.realm.encoder.layer.8.attention.output.dense.bias', 'realm.reader.realm.encoder.layer.5.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.2.attention.self.key.bias', 'realm.reader.realm.encoder.layer.5.attention.self.value.bias', 'realm.reader.realm.encoder.layer.5.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.9.attention.self.key.weight', 'realm.reader.realm.encoder.layer.2.attention.self.query.weight', 'realm.reader.realm.encoder.layer.1.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.6.attention.self.key.bias', 'realm.reader.realm.encoder.layer.5.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.4.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.0.attention.self.value.bias', 'realm.block_emb', 'realm.embedder.realm.embeddings.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.4.intermediate.dense.bias', 'realm.embedder.realm.encoder.layer.2.attention.self.query.weight', 'realm.reader.realm.encoder.layer.5.attention.self.key.weight', 'realm.embedder.realm.encoder.layer.1.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.7.attention.self.key.bias', 'realm.reader.realm.encoder.layer.4.attention.self.key.bias', 'realm.reader.realm.encoder.layer.10.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.6.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.9.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.9.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.5.intermediate.dense.weight', 'realm.embedder.realm.encoder.layer.7.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.10.output.LayerNorm.weight', 'realm.reader.realm.embeddings.word_embeddings.weight', 'realm.embedder.realm.encoder.layer.2.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.5.attention.self.query.weight', 'realm.embedder.realm.encoder.layer.11.attention.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.5.output.dense.bias', 'realm.reader.realm.encoder.layer.5.attention.output.dense.bias', 'realm.embedder.realm.encoder.layer.0.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.8.attention.output.LayerNorm.weight', 'realm.reader.cls.predictions.decoder.bias', 'realm.reader.realm.encoder.layer.8.attention.output.dense.bias', 'realm.embedder.realm.encoder.layer.2.output.dense.bias', 'realm.embedder.realm.encoder.layer.2.attention.self.value.weight', 'realm.reader.realm.encoder.layer.6.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.3.attention.self.value.bias', 'realm.reader.realm.encoder.layer.5.output.dense.weight', 'realm.reader.realm.encoder.layer.7.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.10.attention.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.4.attention.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.6.attention.output.LayerNorm.weight', 'realm.embedder.realm.encoder.layer.0.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.9.attention.self.value.bias', 'realm.embedder.realm.encoder.layer.7.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.9.output.dense.bias', 'realm.embedder.realm.encoder.layer.5.attention.self.value.weight', 'realm.reader.realm.encoder.layer.0.output.LayerNorm.bias', 'realm.embedder.realm.encoder.layer.4.intermediate.dense.weight', 'realm.embedder.realm.encoder.layer.8.output.dense.bias', 'realm.embedder.realm.encoder.layer.11.attention.self.value.weight', 'realm.reader.realm.encoder.layer.1.intermediate.dense.weight', 'realm.reader.realm.encoder.layer.1.attention.self.value.bias', 'realm.reader.realm.encoder.layer.0.attention.self.key.bias', 'realm.reader.realm.encoder.layer.10.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.11.attention.self.key.bias', 'realm.embedder.realm.encoder.layer.6.output.LayerNorm.weight', 'realm.reader.realm.encoder.layer.6.output.dense.bias', 'realm.embedder.realm.encoder.layer.6.attention.self.query.bias', 'realm.reader.realm.encoder.layer.1.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.5.attention.output.dense.weight', 'realm.reader.realm.encoder.layer.3.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.8.attention.self.query.bias', 'realm.reader.realm.encoder.layer.11.attention.self.value.weight', 'realm.embedder.realm.encoder.layer.5.attention.self.query.bias', 'realm.reader.realm.encoder.layer.11.attention.self.query.weight', 'realm.reader.realm.encoder.layer.11.output.dense.bias', 'realm.embedder.realm.encoder.layer.1.attention.self.value.bias', 'realm.reader.cls.predictions.bias', 'realm.reader.realm.encoder.layer.7.attention.self.key.weight', 'realm.reader.realm.encoder.layer.1.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.3.intermediate.dense.bias', 'realm.reader.realm.encoder.layer.5.attention.output.dense.weight', 'realm.embedder.realm.encoder.layer.7.output.dense.bias', 'realm.embedder.realm.encoder.layer.4.output.LayerNorm.bias', 'realm.reader.realm.encoder.layer.1.output.dense.bias', 'realm.reader.realm.encoder.layer.0.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RealmForOpenQA.from_pretrained(\"google/realm-cc-news-pretrained-encoder\", retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load (natural questions) dataset for use during fine-tuning the model\n",
    "\n",
    "def load_natural_questions():\n",
    "    MAX_TOKEN_SIZE = 5\n",
    "    def filter_fn(example):\n",
    "        \"\"\"\n",
    "            Remove answers with length > 5\n",
    "        \"\"\"\n",
    "        for short_ans in example['annotations.short_answers']:\n",
    "            if len(short_ans) != 0:\n",
    "                for i in range(len(short_ans['text'])):\n",
    "                    if short_ans['end_token'][i] - short_ans['start_token'][i] < MAX_TOKEN_SIZE:\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "    def map_fn(example):\n",
    "        \"\"\" Unify dataset structures \"\"\"\n",
    "        return {\n",
    "            'question': example['question.text'],\n",
    "            'answers': [answer['text'] for answer in example['annotations.short_answers']]\n",
    "        }\n",
    "\n",
    "    dataset = load_dataset(\"natural_questions\",\n",
    "                           # cache_dir=\"/run/user/1000/gvfs/smb-share:server=thecloud.local,share=elements_25a3-1\",  # NAS device, I don't have enough space locally\n",
    "                           beam_runner='DirectRunner')  # use default cache location\n",
    "\n",
    "    # get rid of unused columns and flatten the structure\n",
    "    train_dev_set = dataset['train'].train_test_split(test_size=0.2, shuffle=False)\n",
    "\n",
    "    # create train/test/val splits\n",
    "    train_set = train_dev_set['train'].remove_columns(['id', 'document']).flatten()\n",
    "    test_set = train_dev_set['test'].remove_columns(['id', 'document']).flatten()\n",
    "    eval_set = dataset['validation'].remove_columns(['id', 'document']).flatten()\n",
    "\n",
    "    # Perform filtering and mapping\n",
    "    train_set_filtered = train_set.filter(filter_fn).map(map_fn)\n",
    "    test_set_filtered = test_set.filter(filter_fn).map(map_fn)\n",
    "    eval_set_filtered = eval_set.filter(filter_fn).map(map_fn)\n",
    "\n",
    "    # After this, an example in this dataset should contain the following columns:\n",
    "    #     example['question']\n",
    "    #     example['answers'][num_answers]\n",
    "\n",
    "    return train_set_filtered, test_set_filtered, eval_set_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# function to load zsRE qa dataset\n",
    "def load_zsre():\n",
    "    MAX_TOKEN_SIZE = 5\n",
    "\n",
    "    def set_subject_text(example):\n",
    "        \"\"\"\n",
    "        Put the subject of the context into the text\n",
    "            Example: {'question': \"What team does XXX belong to?\",\n",
    "                      ...\n",
    "                      'subject': 'Travis Harmonic'\n",
    "                      'answers': ['New York Islanders']\n",
    "                      }\n",
    "            Into: {'question': \"What team does Travis Harmonic belong to?\",\n",
    "                   'subject': 'Travis Harmonic'\n",
    "                   'answers': ['New York Islanders']}\n",
    "        \"\"\"\n",
    "        return {'question': example['question'].replace('XXX', example['subject']),\n",
    "                'answers': example['answers']}\n",
    "\n",
    "    def filter_empty_ans(example):\n",
    "        \"\"\"\n",
    "        Filter questions that have no answers\n",
    "        \"\"\"\n",
    "        return len(example['answers']) > 0\n",
    "\n",
    "    dataset = load_dataset(\"qa_zre\")  # cache_dir='/tmp/'\n",
    "\n",
    "    print(f\"{get_dataset_infos('qa_zre')}\")\n",
    "\n",
    "    # remove unused columns\n",
    "    train_set = dataset['train'].remove_columns(['relation', 'context']).flatten()\n",
    "    test_set = dataset['test'].remove_columns(['relation', 'context']).flatten()\n",
    "    eval_set = dataset['validation'].remove_columns(['relation', 'context']).flatten()\n",
    "\n",
    "    # map cleaning (we remove the subject column after fixing the answers)\n",
    "    train_filtered = train_set.filter(filter_empty_ans).map(set_subject_text).remove_columns(['subject'])\n",
    "    test_filtered = test_set.filter(filter_empty_ans).map(set_subject_text).remove_columns(['subject'])\n",
    "    eval_filtered = eval_set.filter(filter_empty_ans).map(set_subject_text).remove_columns(['subject'])\n",
    "\n",
    "    # Final dataset should look like:\n",
    "    #  {'question': 'some text',\n",
    "    #   'answers': [number of answers]\n",
    "\n",
    "    return train_filtered, test_filtered, eval_filtered # there's no inflection point t the reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a data collator to use with model\n",
    "# fixme: prefer torch.utils.data.DataCollator\n",
    "class DataCollator(object):\n",
    "    def __init__(self, _tokenizer):\n",
    "        # self.args = args\n",
    "        self.tokenizer = _tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        example = batch[0]\n",
    "        question = example['question']\n",
    "        answer_texts = []\n",
    "\n",
    "        # format the answers properly\n",
    "        for ans in example['answers']:\n",
    "            answer_texts += [ans] if isinstance(ans, str) else ans\n",
    "\n",
    "        # remove duplicates\n",
    "        answer_texts = list(set(answer_texts))\n",
    "        if len(answer_texts) != 0:\n",
    "            answer_ids = self.tokenizer(\n",
    "                answer_texts,\n",
    "                add_special_tokens=False,\n",
    "                return_token_type_ids=False,\n",
    "                return_attention_mask=False,\n",
    "            ).input_ids\n",
    "        else:\n",
    "            answer_ids = [[-1]]\n",
    "\n",
    "        return question, answer_texts, answer_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset qa_zre (/home/patrick/.cache/huggingface/datasets/qa_zre/default/0.1.0/9ad49793a90e5078eb59cf29a88c0b0e893635bbb797a054ac70ab55165bf453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891351e3c9a54719a042fc512077b54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function load_zsre.<locals>.filter_empty_ans at 0x7f104d2b4b80> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'default': DatasetInfo(description='A dataset reducing relation extraction to simple reading comprehension questions\\n', citation='@inproceedings{levy-etal-2017-zero,\\n    title = \"Zero-Shot Relation Extraction via Reading Comprehension\",\\n    author = \"Levy, Omer  and\\n      Seo, Minjoon  and\\n      Choi, Eunsol  and\\n      Zettlemoyer, Luke\",\\n    booktitle = \"Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)\",\\n    month = aug,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/K17-1034\",\\n    doi = \"10.18653/v1/K17-1034\",\\n    pages = \"333--342\",\\n}\\n', homepage='http://nlp.cs.washington.edu/zeroshot', license='', features={'relation': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'subject': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'answers': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='qa_zre', config_name='default', version=0.1.0, splits={'test': SplitInfo(name='test', num_bytes=29409906, num_examples=120000, dataset_name='qa_zre'), 'validation': SplitInfo(name='validation', num_bytes=1481406, num_examples=6000, dataset_name='qa_zre'), 'train': SplitInfo(name='train', num_bytes=2054933851, num_examples=8400000, dataset_name='qa_zre')}, download_checksums={'http://nlp.cs.washington.edu/zeroshot/relation_splits.tar.bz2': {'num_bytes': 516061636, 'checksum': 'e33d0e367b6e837370da17a2d09d217e0a92f8d180f7abb3fd543a2d1726b2b4'}}, download_size=516061636, post_processing_size=None, dataset_size=2085825163, size_in_bytes=2601886799)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9ac6af53054c969a13d9cc652bc66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8400 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e77d14990154711874418b5c92df6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4200000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3977814ed749f39f87de56f66d4924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb402c68e4649a083b224074348f9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5476d2fa0fe14afb9dbfe3c3812590e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bac427ab5b741febb0c6683d2502985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4200000\n",
      "Test size: 60000\n",
      "Validation size: 3000\n"
     ]
    }
   ],
   "source": [
    "# get natural questions dataset for fine-tuning\n",
    "train_set, test_set, eval_set = load_zsre()\n",
    "print(f\"Train size: {len(train_set)}\\nTest size: {len(test_set)}\\nValidation size: {len(eval_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's work with the pretrained version of the model\n",
    "def get_pretrained_realm():\n",
    "    # set activation function to use\n",
    "    config = RealmConfig(hidden_act='gelu_new')\n",
    "    tokenizer = RealmTokenizerFast.from_pretrained(\"google/realm-cc-news-pretrained-embedder\", do_lower_case=True)\n",
    "\n",
    "    # load the new wiki data converted to tf_record blocks to use with the retriever\n",
    "    block_records = convert_tfrecord_to_np(\"/home/patrick/realm/data/wiki-raw/database/blocks.tfr\",\n",
    "                                           # num_block_records=config.num_block_records)  # default value is too big for local machine. Uncomment when running on instance\n",
    "                                           num_block_records=2304037)\n",
    "    print(f\"Size of block records: {len(block_records)}\")\n",
    "    _retriever = RealmRetriever(block_records, tokenizer)\n",
    "\n",
    "    _model = RealmForOpenQA(config=config, retriever=_retriever)\n",
    "\n",
    "    return _model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# test convert tfrecord function\n",
    "block_records = convert_tfrecord_to_np(\"/home/patrick/realm/data/wiki-raw/database/blocks.tfr\", num_block_records=50)\n",
    "print(block_records)\n",
    "del block_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_realm_for_openqa(config=None):\n",
    "    if config is None:\n",
    "        config = RealmConfig(hidden_act='gelu_new')\n",
    "\n",
    "    _retriever = RealmRetriever.from_pretrained('google/realm-orqa-nq-openqa')\n",
    "    _model = RealmForOpenQA.from_pretrained('google/realm-orqa-nq-openqa', retriever=_retriever, config=config)\n",
    "\n",
    "    _model.eval()\n",
    "\n",
    "    return _model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-12 00:52:23.858556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-12 00:52:23.865994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-12 00:52:23.869533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-12 00:52:23.876137: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-12 00:52:23.877922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-12 00:52:23.932681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-12 00:52:23.934355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-12 00:52:24.609281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-12 00:52:24.610925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-12 00:52:24.612300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-12 00:52:24.613670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13584 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of block records: 2304037\n"
     ]
    }
   ],
   "source": [
    "# Run on zsre data\n",
    "# model = get_realm_for_openqa()\n",
    "model = get_pretrained_realm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13353718"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's the default value for num_block_records?\n",
    "RealmConfig().num_block_records\n",
    "# this is too big for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "retriever = model.retriever\n",
    "tokenizer = model.retriever.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1059, 1048, 11407]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's test out our model\n",
    "#\n",
    "question = \"Who was the Upper Canada rebellion leader?\"\n",
    "question_ids = tokenizer([question], return_tensors='pt')\n",
    "\n",
    "answer=\"W L Mackenzie\"\n",
    "\n",
    "answer_ids = tokenizer([answer],\n",
    "                       add_special_tokens=False,\n",
    "                       return_token_type_ids=False,\n",
    "                       return_attention_mask=False).input_ids\n",
    "answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "reader_output, predicted_ans_ids = model(**question_ids,\n",
    "                                         answer_ids=answer_ids,\n",
    "                                         return_dict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ans: the paramount authority in american\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_answer = tokenizer.decode(predicted_ans_ids)\n",
    "print(f\"Ans: {predicted_answer}\")\n",
    "reader_output.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/realm/realm-venv/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec9c399772542ac9e2119e71d113227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data_collator = DataCollator(_tokenizer=tokenizer)\n",
    "\n",
    "train_data_loader = DataLoader(dataset=train_set, batch_size=1, shuffle=True, collate_fn=data_collator)\n",
    "eval_data_loader = DataLoader(dataset=eval_set, batch_size=1, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "# Define a training params, followed by the training loop\n",
    "num_epochs = 2\n",
    "num_training_steps = num_epochs * len(train_data_loader)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-3)\n",
    "\n",
    "lr_scheduler = get_scheduler(\"linear\",\n",
    "                             optimizer=optim,\n",
    "                             num_warmup_steps=0,\n",
    "                             num_training_steps=num_training_steps)\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Normalize answer text strings for metric computation\n",
    "def normalize_answer(text: str):\n",
    "    \"\"\"\n",
    "    Normalize answer\n",
    "    \"\"\"\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "\n",
    "    def remove_articles(t: str):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", t)\n",
    "\n",
    "    def white_space_fix(t: str):\n",
    "        return \" \".join(t.split())\n",
    "\n",
    "    def remove_punct(t: str):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in t if ch not in exclude)\n",
    "\n",
    "    def lower(t: str):\n",
    "         return t.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punct(lower(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize: 'a JambalaYa' => 'jambalaya'\n"
     ]
    }
   ],
   "source": [
    "# test normalize text function\n",
    "\n",
    "print(f\"Normalize: 'a JambalaYa' => '{normalize_answer('JambalaYa')}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's define some metrics training\n",
    "def compute_metrics(labels, predicted_ans, _reader_output):\n",
    "    # Exact match\n",
    "    em = torch.index_select(torch.index_select(_reader_output.reader_correct,\n",
    "                                               dim=0,\n",
    "                                               index=_reader_output.block_idx),\n",
    "                            dim=1,\n",
    "                            index=_reader_output.candidate)\n",
    "\n",
    "    def _true_em(_predicted_ans, references):\n",
    "        return torch.tensor(max([normalize_answer(_predicted_ans) == normalize_answer(ref) for ref in references]))\n",
    "\n",
    "    true_em = _true_em(predicted_ans, labels)\n",
    "\n",
    "    eval_metric = dict(exact_match=em[0][0],\n",
    "                       official_exact_match=true_em,\n",
    "                       reader_oracle=torch.any(_reader_output.reader_correct))\n",
    "\n",
    "    # Top k results\n",
    "    for k in (5, 10, 20, 50):\n",
    "        eval_metric[f\"top_{k}_match\"] = torch.any(_reader_output.retriever_correct[:k])\n",
    "\n",
    "    return eval_metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_realm_for_openqa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13881/2926816998.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_realm_for_openqa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mretriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_realm_for_openqa' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = get_realm_for_openqa()\n",
    "retriever = model.retriever\n",
    "tokenizer = model.tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RealmReaderOutput(loss=tensor(5.9522, grad_fn=<MeanBackward0>), retriever_loss=tensor(5.9522, grad_fn=<MulBackward0>), reader_loss=tensor(0., grad_fn=<MulBackward0>), retriever_correct=tensor([False, False, False,  ..., False, False, False]), reader_correct=tensor([[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]), block_idx=tensor(0), candidate=tensor(47), start_pos=tensor([47]), end_pos=tensor([47]), hidden_states=None, attentions=None),\n",
       " tensor([2633]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids=question.input_ids, answer_ids=answer_ids, return_dict=False)\n",
    "# question  #  = tokenizer(question, return_tensors='pt')\n",
    "# question_ids\n",
    "# torch.tensor(answer_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d5ffc9dd824059898b42841074f9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b28f3152d74bf7bbc8b8ac71fcf734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define train loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # set to train mode\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_data_loader):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        question, answer_texts, answer_ids = batch\n",
    "\n",
    "        question_ids = tokenizer(question, return_tensors='pt').input_ids\n",
    "        reader_output, predicted_ans_ids = model(input_ids=question_ids,\n",
    "                                                 answer_ids=answer_ids,\n",
    "                                                 return_dict=False)\n",
    "\n",
    "        predicted_answer = tokenizer.decode(predicted_ans_ids)\n",
    "\n",
    "        reader_output.loss.backward()\n",
    "\n",
    "        # clip gradients?\n",
    "\n",
    "        optim.step()\n",
    "        lr_scheduler.step()\n",
    "        # print(f\"Epoch: \")\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    for batch in tqdm(eval_data_loader):\n",
    "        question, ans_texts, ans_ids = batch\n",
    "\n",
    "        question_ids = tokenizer(question, return_tensors='pt').input_ids\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=question_ids.to(device),\n",
    "                            answer_ids=ans_ids,\n",
    "                            return_dict=True)\n",
    "\n",
    "            pred_answer = tokenizer.decode(outputs.predicted_answer_ids)\n",
    "            metrics.append(compute_metrics(ans_texts, pred_answer, outputs.reader_output))\n",
    "\n",
    "    stack_metrics = {metric_key: torch.stack((*map(lambda metric: metric[metric_key], metrics), )) for metric_key in metrics[0].keys()}\n",
    "    print(f\"Saving model at checkpoint: {epoch}\")\n",
    "    model.save_pretrained()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
