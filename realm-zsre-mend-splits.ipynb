{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494c4ee9-b1b0-4a8a-8c05-e742686c88a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.15'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf28c5a-8dee-44a3-b861-23ae7ec52a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3461ddba-ffe4-4480-ac09-ab30f2df0df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import torch\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "060a1d0e-3e3d-47fe-b770-45c4a56ef9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbb6bc3-10ac-49bc-a8e1-b06115b908e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17ef0fbe-1f06-4504-8641-f51fef3105fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf88f0fe-9590-4f0d-9739-5072200eff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41edc043-1500-4608-aae7-e5abc3c38c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 15:33:26.555146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 15:33:26.712008: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-22 15:33:27.494168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64::/opt/conda/lib/\n",
      "2022-11-22 15:33:27.494281: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64::/opt/conda/lib/\n",
      "2022-11-22 15:33:27.494291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_scheduler\n",
    "from transformers import RealmForOpenQA, RealmConfig, RealmRetriever, RealmTokenizerFast, RealmScorer\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9436431f-266a-4dfa-8109-8d1f507d7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b2d49-6080-4fb8-ac38-8d307b72e312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58d6d5a9-3a33-4406-9624-8cd37556ca41",
   "metadata": {},
   "source": [
    "## Using the filtered splits used in the MEND paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06578af3-85c5-4441-aaf5-aa7dac0fefb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129a888c-ecef-4626-92d7-0038e6ce4d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration zsre-f642d97352d09fb5\n",
      "Found cached dataset csv (/home/patrick/.cache/huggingface/datasets/csv/zsre-f642d97352d09fb5/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a518d3d2eec4abd8b38bd2225787b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 241523\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 27384\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('data/zsre/', data_files={'train': 'train_filtered.tsv',\n",
    "                                                 'validation': 'dev_filtered.tsv'})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1bb89-4f14-4d55-ad06-2f1b8d3b4430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f14cdb-c297-47c7-b5bc-3314a07388d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the data look like?\n",
    "print(dataset['validation'][20])\n",
    "\n",
    "# Seems like each example is a question answer pair,\n",
    "# remever to wrap them in list notation as expected \n",
    "# by the realm tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4104ec6-3a1e-4dc8-85f4-c265e5d6d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset \n",
    "dataset.save_to_disk('data/zsre/zsre_hf.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38a92c-f2f4-4aca-9878-9389294ba2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3f90dd0-44b7-4529-ad6a-1cf4913b3cca",
   "metadata": {},
   "source": [
    "## Evalutation set, keeping multiple answers as they do in MEND\n",
    "\n",
    "### (but stripping very similar questions with the same answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "33be7197-73f6-4d2f-b9f3-e26c4c8b07e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ece9db3630a4b9dace774538fbf02b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answers'],\n",
       "        num_rows: 44499\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answers'],\n",
       "        num_rows: 7983\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate with only the validation dataset for now\n",
    "\n",
    "multi_dataset = load_dataset('data/zsre/', data_files={'train': 'train_multi_alternatives.tsv',\n",
    "                                                       'validation': 'dev_multi_alternatives.tsv'})\n",
    "multi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "db7b9d84-a64c-4010-aca3-246b52409170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's undo the list/string shenanigans!\n",
    "def undo_string_list_shenaningans(example):\n",
    "    return {'question': example['question'], 'answers': literal_eval(example['answers'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5ec0dfb6-b16a-427f-9c27-ad41bec0a083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What university did Watts Humphrey attend?',\n",
       " 'answers': ['Illinois Institute of Technology',\n",
       "  'Yale University',\n",
       "  'University of Chicago',\n",
       "  \"King's College London\",\n",
       "  'University of Michigan']}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test shenanigans function \n",
    "undo_string_list_shenaningans(multi_dataset['validation'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "623b9130-65e3-478a-b6dc-e3e0a6562e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_dataset['validation'] = multi_dataset['validation'].map(undo_string_list_shenaningans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3e0a8dac-017c-4152-8331-517b294c01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_dataset['train'] = multi_dataset['train'].map(undo_string_list_shenaningans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3adfd-ab9a-42b9-9a51-6172e0f56f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd783faa-4721-4517-8da7-7221ce8864cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ae512f7-d1b9-4583-a8bd-3be1c9c059b2",
   "metadata": {},
   "source": [
    "### Dataloaders and collators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bfc61-a5a8-473f-9ba5-5d2d98004ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ed9e9b99-4343-4926-83d8-1f0fd194294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset['train'], batch_size=1) # complains with a batch size > 1\n",
    "eval_dataloader = torch.utils.data.DataLoader(dataset['validation'], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5d492-ac5e-43e4-b3c7-8ea9e8b56ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9305de9c-20c3-4535-9988-5b17b468886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember these ones return multiple answers at a time, choose one \n",
    "train_multi_dataloader = torch.utils.data.DataLoader(multi_dataset['train'], batch_size=1)\n",
    "eval_multi_dataloader = torch.utils.data.DataLoader(multi_dataset['validation'], batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8befca4d-63ad-4a69-a517-9e2320961dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ae64a0d-5905-44ec-bd17-f6c33bc87502",
   "metadata": {},
   "source": [
    "## Format retrieval data for pretrained retriever checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e36b33-634e-4dbe-af40-26e4a554562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.realm.retrieval_realm import convert_tfrecord_to_np\n",
    "\n",
    "block_records = convert_tfrecord_to_np('data/wiki/enwiki-20181220/blocks.tfr', RealmConfig().num_block_records)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de19f64-79a1-43e9-b15f-b72e0baf6732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078bdd2c-e1a5-4dba-9d0c-92f31f937a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the block records object \n",
    "np.save(\"20181220_records\", block_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "53ace6f9-1fab-490a-86f0-4ee0b85a6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we've already saved this file, read it in \n",
    "block_records = np.load(\"data/block_records.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d4ebe0fc-92a0-44bb-9ecc-1d7d9141bb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13353718"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ca52d-2358-4e12-8d36-59502cda4c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "078f8cd0-3e08-4bf8-bcd1-74ce039e9203",
   "metadata": {},
   "source": [
    "## Finetune openqa checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "47fabf4c-43ef-4b99-b82c-9efdba5a0156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up simple logging to file so we don't get overwhelmed in notebook \n",
    "logging.basicConfig(filename=f'logs/train-{time.strftime(\"%m-%d-%YT%H:%M:%S\", time.localtime())}.log',\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "logging.info(\"Setting up training...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b1dd0c83-8adb-4f3c-bf72-4cf2d5624173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finetuned checkpoint\n",
    "checkpoint = \"google/realm-orqa-nq-openqa\"\n",
    "\n",
    "# For pretrained on cc-news weights\n",
    "ft_checkpoint = \"google/realm-cc-news-pretrained-openqa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab851e6-a4a8-40e3-838e-71e563d8a6be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c2140398-6d2c-4dc9-b19a-362dd9df829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment next line for REALM pretrained in wiki\n",
    "# tokenizer = RealmTokenizerFast.from_pretrained(checkpoint)\n",
    "\n",
    "# uncomment below for REALM tokenizer pretrained on cc-news \n",
    "tokenizer = RealmTokenizerFast.from_pretrained(ft_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a80cbd45-4cf0-4c39-ae0c-b3a1e8b0896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment line below for orqa retriever \n",
    "# retriever = RealmRetriever.from_pretrained(checkpoint)\n",
    "\n",
    "# uncomment line below for retriever with own database to retrieve from\n",
    "retriever = RealmRetriever(block_records, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c0c6dd5c-6cb8-435b-b924-2620f702ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below for orqa model \n",
    "# model = RealmForOpenQA.from_pretrained(checkpoint, retriever)\n",
    "\n",
    "# uncomment below for model pretrained on cc-news\n",
    "model = RealmForOpenQA.from_pretrained(ft_checkpoint, retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cdba77-302e-40b5-aebf-281a5277c84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fd1ebb4c-6395-49a1-be96-4e5b4591f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Test\n",
    "#\n",
    "\n",
    "question = \"Who is the pioneer in modern computer science?\"\n",
    "question_ids = tokenizer([question], return_tensors=\"pt\")\n",
    "\n",
    "answer_ids = tokenizer(\n",
    "    [\"alan mathison turing\"],\n",
    "    add_special_tokens=False,\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=False,\n",
    "    return_tensors=\"pt\"\n",
    ").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f7c7b2bf-eb6e-449b-9760-35c0b294ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_output, predicted_answer_ids = model(**question_ids,  # .to(device),\n",
    "                                            answer_ids=answer_ids,  # .to(device),\n",
    "                                            return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "31802cf7-014b-4f02-9db9-78e605c714b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computer science and software engineering ; both fields study software'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(predicted_answer_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b8cbe704-efda-4656-82f5-a61cfc5d1705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2794)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_output.candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0038703f-5f0c-4744-8817-b03052dbbb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.any(reader_output.reader_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b43c10-a850-4989-95ad-44c8ae240e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628fceef-6aca-4cda-953c-706618d38938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "aebea79c-3f41-4c98-b2fb-6829cf8d0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from: https://github.com/huggingface/transformers/blob/e239fc3b0baf1171079a5e0177a69254350a063b/examples/pytorch/language-modeling/run_mlm_no_trainer.py#L456-L468\n",
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.01,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796be8e-2f00-4c15-83aa-518811666e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b0d188b0-4871-4fe9-82df-2e012085bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    eps=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb2b10-8223-4f85-9b56-39fe33d5e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "80106803-3ccf-4d72-95df-64d9dbf17e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2  # epochs \n",
    "\n",
    "num_steps = len(train_dataloader) * num_epochs  # total steps to set up scheduler \n",
    "\n",
    "global_step = 1  # tracker for number of steps \n",
    "\n",
    "checkpoint_interval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4764c901-93a4-4f8c-a399-b646be2398f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c77e553e-f077-4a67-97fe-e2750699ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning rate scheduler \n",
    "\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=10000,\n",
    "    num_training_steps=num_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e454e-c830-450f-8f55-33d117ccec48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7c582a65-d27e-4c71-96cc-86711f7bf408",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412831c-fb87-4754-9323-8c35acf68cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741acbe3-ca19-40c2-9ef9-3a0114cfbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "07e2df14-b48f-4a69-9c4b-a305bb5fc27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bb in train_multi_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "55ad62cd-72de-482b-be22-020db1ce1717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Who is Adoration of the Trinity by?']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb['question']\n",
    "\n",
    "# bb['answers'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0ed5420f-c5da-4466-8e04-1f032bf5e19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('embedder.realm.embeddings.word_embeddings.weight',\n",
       " Parameter containing:\n",
       " tensor([[-0.0095, -0.0572, -0.0246,  ..., -0.0184, -0.0346, -0.0091],\n",
       "         [-0.0109, -0.0558, -0.0300,  ..., -0.0156, -0.0372, -0.0099],\n",
       "         [-0.0183, -0.0583, -0.0303,  ..., -0.0153, -0.0390, -0.0030],\n",
       "         ...,\n",
       "         [-0.0202, -0.0517, -0.0125,  ..., -0.0040, -0.0141, -0.0231],\n",
       "         [-0.0429, -0.0524, -0.0018,  ...,  0.0146, -0.0129, -0.0088],\n",
       "         [-0.0125, -0.0907, -0.0150,  ...,  0.0255, -0.0366,  0.0690]],\n",
       "        device='cuda:0', requires_grad=True))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325c6fe-e62d-4012-a4f2-eecc3b98dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761af219d1794ba7b8b0ada322ebeffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up training loop\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(train_multi_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # remember the batch is size 1 with 1 question and 1 answer\n",
    "        question = batch['question'][0]\n",
    "        question_ids = tokenizer(question, return_tensors='pt')\n",
    "\n",
    "        answer = batch['answers'][0][0]\n",
    "        answer_ids = tokenizer([answer],\n",
    "                               add_special_tokens=False,\n",
    "                               return_attention_mask=False,\n",
    "                               return_token_type_ids=False,\n",
    "                               return_tensors='pt').input_ids\n",
    "        \n",
    "        reader_output, predicted_ans_ids = model(**question_ids.to(device),\n",
    "                                                 answer_ids=answer_ids.to(device),\n",
    "                                                 return_dict=False)\n",
    "        \n",
    "        predicted_answer = tokenizer.decode(predicted_ans_ids)\n",
    "        \n",
    "        # log to tensorboard \n",
    "        writer.add_scalar(\"Reader loss\", reader_output.loss.item())\n",
    "        writer.add_scalar(\"Retriever loss\", reader_output.retriever_loss.item())\n",
    "        \n",
    "        for name, weight in model.named_parameters():\n",
    "            if weight.grad is not None:\n",
    "                writer.add_histogram(name, weight, epoch)\n",
    "                writer.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "        \n",
    "        # backward please \n",
    "        reader_output.loss.backward()\n",
    "        \n",
    "        clip_grad_norm_(model.parameters(), 1.0, norm_type=2.0, error_if_nonfinite=False)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        logging.info(\n",
    "            f\"Epoch: {epoch}, \"\n",
    "            f\"Step: {global_step}, \"\n",
    "            f\"Retriever Loss: {reader_output.retriever_loss.mean()}, \"\n",
    "            f\"Reader Loss: {reader_output.reader_loss.mean()}\\n\"\n",
    "            f\"\\tQuestion: {batch['question'][0]}, Gold Answer: {answer}, Predicted Answer: {predicted_answer}\"\n",
    "        )\n",
    "        \n",
    "        if global_step % checkpoint_interval == 0:\n",
    "            logging.info(f\"Saving checkpint at step {global_step}\")\n",
    "            \n",
    "            model.save_pretrained(f\"checkpoints/short/checkpoint-{global_step}\")\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step >= num_steps:\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d002464-df78-43b6-94d5-533c2ae95622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "model.save_pretrained('trained/zsre/v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24233f8c-78e7-432b-9b87-c98777600af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c065631-2402-4381-a1de-de2531e7dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "83b8273e-8a2c-4205-a18e-af03b32c3109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f72675-f278-49eb-9b5d-9fb59e0d6d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1418d8-5fa5-4933-9439-5592cc137112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00f2b00a-5299-4f46-a778-afdeaa851524",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b9385019-3f00-489f-8861-a03cd4af5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e68e13-2742-4388-970c-4ed80f57421d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8724b600-feaa-49e5-b718-dfea68804b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"\n",
    "        Normalize answer. (Copied from ORQA codebase)\n",
    "    \"\"\"\n",
    "    s = unicodedata.normalize(\"NFD\", s)\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd07d66c-6f51-46a3-9081-861d09a12c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alan mathison turing'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test normalize ans\n",
    "normalize_answer(\"Alan Mathison Turing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bf14f-a986-441e-a4e7-8429d0c247d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9427bd4-3bf4-4e75-afed-ad3f9f2ad048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eval_metrics(labels, predicted_answer, reader_output):\n",
    "    # First, try to find exact match\n",
    "    exact_match = torch.index_select(\n",
    "        torch.index_select(reader_output.reader_correct,\n",
    "                           dim=0,\n",
    "                           index=reader_output.block_idx),\n",
    "        dim=1,\n",
    "        index=reader_output.candidate\n",
    "    )\n",
    "    \n",
    "    def _official_exact_match(predicted_answer, references):\n",
    "        return torch.tensor(\n",
    "            max(\n",
    "                [normalize_answer(predicted_answer) == normalize_answer(reference) for reference in references]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    \n",
    "    official_em = _official_exact_match(predicted_answer, labels)\n",
    "    \n",
    "    eval_metric = dict(\n",
    "        exact_match=exact_match[0][0],\n",
    "        official_exact_match=official_em,\n",
    "        reader_oracle=torch.any(reader_output.reader_correct)\n",
    "    )\n",
    "    \n",
    "    # Get top matches \n",
    "    for k in (5, 10, 50, 100, 500, 1000, 5000):\n",
    "        eval_metric[f\"top_{k}_match\"] = torch.any(reader_output.retriever_correct[:k])\n",
    "        \n",
    "    return eval_metric\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10202332-73c8-4a1f-872a-24b62b5acfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d9f6530-fd29-4572-b205-58bd4e4f93a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': tensor(False, device='cuda:0'),\n",
       " 'official_exact_match': tensor(True),\n",
       " 'reader_oracle': tensor(False, device='cuda:0'),\n",
       " 'top_5_match': tensor(False, device='cuda:0'),\n",
       " 'top_10_match': tensor(False, device='cuda:0'),\n",
       " 'top_50_match': tensor(False, device='cuda:0'),\n",
       " 'top_100_match': tensor(False, device='cuda:0'),\n",
       " 'top_500_match': tensor(False, device='cuda:0'),\n",
       " 'top_1000_match': tensor(False, device='cuda:0'),\n",
       " 'top_5000_match': tensor(False, device='cuda:0')}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test compute metrics\n",
    "compute_eval_metrics([\"Alan Mathison Turing\"],\n",
    "                     tokenizer.decode(predicted_answer_ids),\n",
    "                     reader_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb4bfbab-6724-4f38-b709-12173819be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set searcher and reader beam size to same values as paper\n",
    "reader_beam_size = 5\n",
    "searcher_beam_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f95945b-b7ac-45af-8513-37002fa080e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8e85a-bbc1-4a8e-94b1-c6b06a06562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b1e11-a6fe-421f-aa81-27fa949cae28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c1e61bdc-2ac0-4fb7-8d1e-ff9b548f32ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all metrics\n",
    "all_metrics = []\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cdeda9b2-7a19-47f8-98d5-ff1d0149be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions for script eval\n",
    "pred_file = open('data/for_eval/model_predictions.txt', 'w')\n",
    "ground_truth_file = open('data/for_eval/ground_truth.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0268b53f-4cb4-48ac-881b-1cb40246fd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574d7717ae2b4d99b430b20a9206c71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The batch_size of the inputs must be 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [137], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m answer_ids \u001b[38;5;241m=\u001b[39m tokenizer(ebatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m                        add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m                        return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m                        return_token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                        return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m                        padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 15\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mquestion_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43manswer_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manswer_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m predicted_answer \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs\u001b[38;5;241m.\u001b[39mpredicted_answer_ids)\n\u001b[1;32m     21\u001b[0m all_metrics\u001b[38;5;241m.\u001b[39mappend(compute_eval_metrics(ebatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m], predicted_answer, outputs\u001b[38;5;241m.\u001b[39mreader_output))\n",
      "File \u001b[0;32m~/retrieval-augmented-models/rvenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/retrieval-augmented-models/rvenv/lib/python3.9/site-packages/transformers/models/realm/modeling_realm.py:1798\u001b[0m, in \u001b[0;36mRealmForOpenQA.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, answer_ids, return_dict)\u001b[0m\n\u001b[1;32m   1795\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe batch_size of the inputs must be 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1800\u001b[0m question_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder(\n\u001b[1;32m   1801\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids, token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m )\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;66;03m# [1, projection_size]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The batch_size of the inputs must be 1."
     ]
    }
   ],
   "source": [
    "# Set up eval\n",
    "model.eval()\n",
    "\n",
    "for ebatch in tqdm(eval_dataloader):\n",
    "    question_ids = tokenizer(ebatch['question'], return_tensors='pt', padding=True)\n",
    "    \n",
    "    answer_ids = tokenizer(ebatch['answer'],\n",
    "                           add_special_tokens=False,\n",
    "                           return_attention_mask=False,\n",
    "                           return_token_type_ids=False,\n",
    "                           return_tensors='pt',\n",
    "                           padding=True).input_ids\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**question_ids.to(device),\n",
    "                        answer_ids=answer_ids.to(device),\n",
    "                        return_dict=True)\n",
    "\n",
    "    predicted_answer = tokenizer.decode(outputs.predicted_answer_ids)\n",
    "    \n",
    "    all_metrics.append(compute_eval_metrics(ebatch['answer'], predicted_answer, outputs.reader_output))\n",
    "    \n",
    "    pred_file.write(predicted_answer)\n",
    "    pred_file.write('\\n')\n",
    "    \n",
    "    ground_truth_file.write(ebatch['answer'][0])\n",
    "    ground_truth_file.write('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de4495cf-6635-42fc-8c11-5b9819fb1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file.close()\n",
    "ground_truth_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2feea69f-742e-493c-9cb1-9d54e1568e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_metrics = {\n",
    "    metric_key: torch.stack((*map(lambda metrics: metrics[metric_key], all_metrics),)) for metric_key in all_metrics[0].keys()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5628f108-23f2-47f1-b311-a64322b110d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Official EM: 0.26698071866783524\n",
      "Exact Match: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Official EM: {len(((stacked_metrics['official_exact_match'] == True).nonzero(as_tuple=True)[0])) / len(stacked_metrics['official_exact_match']) }\")\n",
    "\n",
    "\n",
    "print(f\"Exact Match: {len(((stacked_metrics['exact_match'] == True).nonzero(as_tuple=True)[0])) / len(stacked_metrics['exact_match'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe3fbc-badf-4278-8b5a-ea23c834cb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b408e73-611a-4e67-8b30-a1e89ab9131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefer huggingface's evaluate library\n",
    "preds, labels = [], []\n",
    "with open('data/for_eval/model_predictions.txt', 'r') as f:\n",
    "    preds = [normalize_answer(line) for line in f]\n",
    "f.close()\n",
    "\n",
    "with open('data/for_eval/ground_truth.txt', 'r') as p:\n",
    "    labels = [normalize_answer(line) for line in p]\n",
    "p.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "153acf8d-09d6-4f23-8fa8-3059e455fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5ae176bfc04690af94ff2c1caf6dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.26698071866783524}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set metric to use\n",
    "em_metric = load('exact_match')\n",
    "\n",
    "results = em_metric.compute(predictions=preds, references=labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a9784-77e5-4ac0-ae8a-f8b0fea1f59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395ff80-a460-4f9a-91a0-828968691cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c00d2ff4-67d7-404d-aa63-2076eb484432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56d85cbe-32e8-457a-a34a-41d356630a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27384"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_strings = []\n",
    "\n",
    "for b in eval_dataloader:\n",
    "    answers_strings.append(b['answer'][0])\n",
    "\n",
    "len(answers_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ff480ce-bcf1-4716-aa88-ac08e59f6448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Illinois Institute of Technology', 'Lecanorales', 'defender']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_strings[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbaee2fe-b641-400e-b8c5-0dc15aaf3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_counts = Counter(answers_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9cebe298-fcb5-42ef-93ac-ff5f92b0dce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Antarctica', 478),\n",
       " ('French', 430),\n",
       " ('female', 321),\n",
       " ('midfielder', 188),\n",
       " ('human', 166),\n",
       " ('soprano', 155),\n",
       " ('World War II', 145),\n",
       " ('heart attack', 140),\n",
       " ('male', 137),\n",
       " ('piano', 136)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_counts.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa21ca5-f8ad-4f80-9035-bd27dfa6bfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5d96b-75eb-4ea5-8427-7399d5f4652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times the same answer appear in the data?\n",
    "counts = dict(int)\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    if batch['answer'] in counts:\n",
    "        counts[[batch['answer']] += 1\n",
    "           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c3c96-6363-40e6-8765-66f479637f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cedc2c6-d26b-4257-b3b6-84d8503558d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43615b-5741-452c-af24-5f1258114daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
