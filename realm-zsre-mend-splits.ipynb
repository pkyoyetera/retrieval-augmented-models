{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494c4ee9-b1b0-4a8a-8c05-e742686c88a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.15'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf28c5a-8dee-44a3-b861-23ae7ec52a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3461ddba-ffe4-4480-ac09-ab30f2df0df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import torch\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060a1d0e-3e3d-47fe-b770-45c4a56ef9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bbb6bc3-10ac-49bc-a8e1-b06115b908e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ef0fbe-1f06-4504-8641-f51fef3105fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf88f0fe-9590-4f0d-9739-5072200eff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41edc043-1500-4608-aae7-e5abc3c38c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 16:39:36.523547: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 16:39:37.067825: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-30 16:39:38.986823: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64::/opt/conda/lib/\n",
      "2022-11-30 16:39:38.987772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64::/opt/conda/lib/\n",
      "2022-11-30 16:39:38.987784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_scheduler\n",
    "from transformers import RealmForOpenQA, RealmConfig, RealmRetriever, RealmTokenizerFast, RealmScorer\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9436431f-266a-4dfa-8109-8d1f507d7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b2d49-6080-4fb8-ac38-8d307b72e312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58d6d5a9-3a33-4406-9624-8cd37556ca41",
   "metadata": {},
   "source": [
    "## Using the filtered splits used in the MEND paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06578af3-85c5-4441-aaf5-aa7dac0fefb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129a888c-ecef-4626-92d7-0038e6ce4d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration zsre-f642d97352d09fb5\n",
      "Found cached dataset csv (/home/patrick/.cache/huggingface/datasets/csv/zsre-f642d97352d09fb5/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a518d3d2eec4abd8b38bd2225787b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 241523\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 27384\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('data/zsre/', data_files={'train': 'train_filtered.tsv',\n",
    "                                                 'validation': 'dev_filtered.tsv'})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1bb89-4f14-4d55-ad06-2f1b8d3b4430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f14cdb-c297-47c7-b5bc-3314a07388d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the data look like?\n",
    "print(dataset['validation'][20])\n",
    "\n",
    "# Seems like each example is a question answer pair,\n",
    "# remever to wrap them in list notation as expected \n",
    "# by the realm tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4104ec6-3a1e-4dc8-85f4-c265e5d6d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset \n",
    "dataset.save_to_disk('data/zsre/zsre_hf.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38a92c-f2f4-4aca-9878-9389294ba2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3f90dd0-44b7-4529-ad6a-1cf4913b3cca",
   "metadata": {},
   "source": [
    "## Evalutation set, keeping multiple answers as they do in MEND\n",
    "\n",
    "### (but stripping very similar questions with the same answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33be7197-73f6-4d2f-b9f3-e26c4c8b07e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration zsre-af38a83f555970c7\n",
      "Found cached dataset csv (/home/patrick/.cache/huggingface/datasets/csv/zsre-af38a83f555970c7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d2166795ed403abfd4b905f066fc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answers'],\n",
       "        num_rows: 44499\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answers'],\n",
       "        num_rows: 7983\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate with only the validation dataset for now\n",
    "\n",
    "multi_dataset = load_dataset('data/zsre/', data_files={'train': 'train_multi_alternatives.tsv',\n",
    "                                                       'validation': 'dev_multi_alternatives.tsv'})\n",
    "multi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db7b9d84-a64c-4010-aca3-246b52409170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's undo the list/string shenanigans!\n",
    "def undo_string_list_shenaningans(example):\n",
    "    return {'question': example['question'], 'answers': literal_eval(example['answers'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ec0dfb6-b16a-427f-9c27-ad41bec0a083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "{'question': 'What university did Watts Humphrey attend?', 'answers': '[\\'Illinois Institute of Technology\\', \\'Yale University\\', \\'University of Chicago\\', \"King\\'s College London\", \\'University of Michigan\\']'}\n",
      "\n",
      "After:\n",
      "{'question': 'What university did Watts Humphrey attend?', 'answers': ['Illinois Institute of Technology', 'Yale University', 'University of Chicago', \"King's College London\", 'University of Michigan']}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before:\\n{multi_dataset['validation'][0]}\\n\")\n",
    "\n",
    "# test shenanigans function \n",
    "print(f\"After:\\n{undo_string_list_shenaningans(multi_dataset['validation'][0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "623b9130-65e3-478a-b6dc-e3e0a6562e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/patrick/.cache/huggingface/datasets/csv/zsre-af38a83f555970c7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-da1ac86eb5b3752e.arrow\n"
     ]
    }
   ],
   "source": [
    "multi_dataset['validation'] = multi_dataset['validation'].map(undo_string_list_shenaningans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0a8dac-017c-4152-8331-517b294c01b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/patrick/.cache/huggingface/datasets/csv/zsre-af38a83f555970c7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-ca2ed67407fe5cd7.arrow\n"
     ]
    }
   ],
   "source": [
    "multi_dataset['train'] = multi_dataset['train'].map(undo_string_list_shenaningans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3adfd-ab9a-42b9-9a51-6172e0f56f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd783faa-4721-4517-8da7-7221ce8864cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ae512f7-d1b9-4583-a8bd-3be1c9c059b2",
   "metadata": {},
   "source": [
    "### Dataloaders and collators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bfc61-a5a8-473f-9ba5-5d2d98004ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ed9e9b99-4343-4926-83d8-1f0fd194294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset['train'], batch_size=1) # complains with a batch size > 1\n",
    "eval_dataloader = torch.utils.data.DataLoader(dataset['validation'], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5d492-ac5e-43e4-b3c7-8ea9e8b56ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9305de9c-20c3-4535-9988-5b17b468886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember these ones return multiple answers at a time, choose one \n",
    "train_multi_dataloader = torch.utils.data.DataLoader(multi_dataset['train'], batch_size=2)\n",
    "eval_multi_dataloader = torch.utils.data.DataLoader(multi_dataset['validation'], batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8befca4d-63ad-4a69-a517-9e2320961dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ae64a0d-5905-44ec-bd17-f6c33bc87502",
   "metadata": {},
   "source": [
    "## Format retrieval data for pretrained retriever checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e36b33-634e-4dbe-af40-26e4a554562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.realm.retrieval_realm import convert_tfrecord_to_np\n",
    "\n",
    "block_records = convert_tfrecord_to_np('data/wiki/enwiki-20181220/blocks.tfr', RealmConfig().num_block_records)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de19f64-79a1-43e9-b15f-b72e0baf6732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078bdd2c-e1a5-4dba-9d0c-92f31f937a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the block records object \n",
    "np.save(\"20181220_records\", block_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53ace6f9-1fab-490a-86f0-4ee0b85a6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we've already saved this file, read it in \n",
    "block_records = np.load(\"data/block_records.npy\", allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4ebe0fc-92a0-44bb-9ecc-1d7d9141bb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13353718"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ca52d-2358-4e12-8d36-59502cda4c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "078f8cd0-3e08-4bf8-bcd1-74ce039e9203",
   "metadata": {},
   "source": [
    "## Finetune openqa checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47fabf4c-43ef-4b99-b82c-9efdba5a0156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up simple logging to file so we don't get overwhelmed in notebook \n",
    "logging.basicConfig(filename=f'logs/train-{time.strftime(\"%m-%d-%YT%H:%M:%S\", time.localtime())}.log',\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "logging.info(\"Setting up training...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1dd0c83-8adb-4f3c-bf72-4cf2d5624173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finetuned checkpoint\n",
    "checkpoint = \"google/realm-orqa-nq-openqa\"\n",
    "\n",
    "# For pretrained on cc-news weights\n",
    "ft_checkpoint = \"google/realm-cc-news-pretrained-openqa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab851e6-a4a8-40e3-838e-71e563d8a6be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae6e4589-4600-46e6-9584-a305a4662688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the beam size for the searcher a little lower to make training faster, \n",
    "# though it does lead to lower accuracy \n",
    "config = RealmConfig(searcher_beam_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2140398-6d2c-4dc9-b19a-362dd9df829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment next line for REALM pretrained in wiki\n",
    "# tokenizer = RealmTokenizerFast.from_pretrained(checkpoint)\n",
    "\n",
    "# uncomment below for REALM tokenizer pretrained on cc-news \n",
    "tokenizer = RealmTokenizerFast.from_pretrained(ft_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a80cbd45-4cf0-4c39-ae0c-b3a1e8b0896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment line below for orqa retriever \n",
    "# retriever = RealmRetriever.from_pretrained(checkpoint)\n",
    "\n",
    "# uncomment line below for retriever with own database to retrieve from\n",
    "retriever = RealmRetriever(block_records, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0c6dd5c-6cb8-435b-b924-2620f702ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below for orqa model \n",
    "# model = RealmForOpenQA.from_pretrained(checkpoint, retriever)\n",
    "\n",
    "# uncomment below for model pretrained on cc-news\n",
    "model = RealmForOpenQA.from_pretrained(ft_checkpoint, retriever, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cdba77-302e-40b5-aebf-281a5277c84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd1ebb4c-6395-49a1-be96-4e5b4591f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Test\n",
    "#\n",
    "\n",
    "question = \"What war did Oscar Veniah Dayton fight in?\"\n",
    "question_ids = tokenizer([question], return_tensors=\"pt\")\n",
    "\n",
    "answer_ids = tokenizer(\n",
    "    [\"american civil war\"],\n",
    "    # add_special_tokens=False,\n",
    "    # return_token_type_ids=False,\n",
    "    # return_attention_mask=False,\n",
    "    return_tensors=\"pt\"\n",
    ").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7c7b2bf-eb6e-449b-9760-35c0b294ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_output, predicted_answer_ids = model(**question_ids,  # .to(device),\n",
    "                                            answer_ids=answer_ids,  # .to(device),\n",
    "                                            return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d67f8e3-e855-4efe-8dda-dfc4b8f92ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Who is Adoration of the Trinity by?',\n",
       " 'The manufacturer of Colt King Cobra was who?']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b06a786-ca71-43b0-9be5-198c7e0bb489",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.batch_encode_candidates([bb['question']], )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9a32e-5616-447f-8fe2-afda0451db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(**tokens, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31802cf7-014b-4f02-9db9-78e605c714b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'american civil war'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(predicted_answer_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8cbe704-efda-4656-82f5-a61cfc5d1705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(699)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_output.candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0038703f-5f0c-4744-8817-b03052dbbb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.any(reader_output.reader_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b43c10-a850-4989-95ad-44c8ae240e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628fceef-6aca-4cda-953c-706618d38938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aebea79c-3f41-4c98-b2fb-6829cf8d0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from: https://github.com/huggingface/transformers/blob/e239fc3b0baf1171079a5e0177a69254350a063b/examples/pytorch/language-modeling/run_mlm_no_trainer.py#L456-L468\n",
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.01,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796be8e-2f00-4c15-83aa-518811666e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0d188b0-4871-4fe9-82df-2e012085bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    eps=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65fb2b10-8223-4f85-9b56-39fe33d5e909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/retrieval-augmented-models/rvenv/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80106803-3ccf-4d72-95df-64d9dbf17e53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_multi_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# epochs \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_multi_dataloader\u001b[49m) \u001b[38;5;241m*\u001b[39m num_epochs  \u001b[38;5;66;03m# total steps to set up scheduler \u001b[39;00m\n\u001b[1;32m      5\u001b[0m global_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# tracker for number of steps \u001b[39;00m\n\u001b[1;32m      7\u001b[0m checkpoint_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_multi_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 2  # epochs \n",
    "\n",
    "num_steps = len(train_multi_dataloader) * num_epochs  # total steps to set up scheduler \n",
    "\n",
    "global_step = 1  # tracker for number of steps \n",
    "\n",
    "checkpoint_interval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4764c901-93a4-4f8c-a399-b646be2398f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e553e-f077-4a67-97fe-e2750699ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning rate scheduler \n",
    "\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=10000,\n",
    "    num_training_steps=num_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e454e-c830-450f-8f55-33d117ccec48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c582a65-d27e-4c71-96cc-86711f7bf408",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0debcc1a-a6b0-4372-b23c-0ef77eedd3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5070,  8785, 10929, 28639]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412831c-fb87-4754-9323-8c35acf68cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, input_to_model=[question_ids.input_ids,\n",
    "                                        answer_ids.to(device)])\n",
    "#**question_ids.to(device), answer_ids=answer_ids.to(device), return_dict=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741acbe3-ca19-40c2-9ef9-3a0114cfbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3201febe-e1e9-4222-9481-428fd4e6c6ab",
   "metadata": {},
   "source": [
    "### Tesdting data batching formats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07e2df14-b48f-4a69-9c4b-a305bb5fc27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bb in train_multi_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55ad62cd-72de-482b-be22-020db1ce1717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Who is Adoration of the Trinity by?'],\n",
       " ['The manufacturer of Colt King Cobra was who?']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = []\n",
    "\n",
    "for item in bb['question']:\n",
    "    questions.append([item])\n",
    "\n",
    "questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d4ef7b7c-a315-49df-9541-a1807d7a935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 120])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question = bb['question']\n",
    "question_ids = tokenizer.batch_encode_candidates(questions,\n",
    "                                                 return_tensors='pt',\n",
    "                                                 max_length=120,\n",
    "                                                 padding=True)\n",
    "\n",
    "question_ids.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b79f5f0a-0586-45f9-b21d-3d3daf886655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 120])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = []\n",
    "\n",
    "for ans in bb['answers'][0]:\n",
    "    answers.append([ans])\n",
    "# answers\n",
    "answer_ids = tokenizer.batch_encode_candidates(answers,\n",
    "                                               # add_special_tokens=False,\n",
    "                                               # return_attention_mask=False,\n",
    "                                               # return_token_type_ids=False,\n",
    "                                               return_tensors='pt',\n",
    "                                               max_length=120,\n",
    "                                               padding=True).input_ids\n",
    "answer_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab511802-fea1-4226-bc87-e472c539cbaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The batch_size of the inputs must be 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reader_output, predicted_ans_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mquestion_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43manswer_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manswer_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/retrieval-augmented-models/rvenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/retrieval-augmented-models/rvenv/lib/python3.9/site-packages/transformers/models/realm/modeling_realm.py:1798\u001b[0m, in \u001b[0;36mRealmForOpenQA.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, answer_ids, return_dict)\u001b[0m\n\u001b[1;32m   1795\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe batch_size of the inputs must be 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1800\u001b[0m question_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder(\n\u001b[1;32m   1801\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids, token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m )\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;66;03m# [1, projection_size]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The batch_size of the inputs must be 1."
     ]
    }
   ],
   "source": [
    "\n",
    "reader_output, predicted_ans_ids = model(**question_ids,\n",
    "                                         answer_ids=answer_ids,\n",
    "                                         return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ed5420f-c5da-4466-8e04-1f032bf5e19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('embedder.realm.embeddings.word_embeddings.weight',\n",
       " Parameter containing:\n",
       " tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba7a91ff-29ce-4c48-93e3-62597bf7a0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(weight).all().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325c6fe-e62d-4012-a4f2-eecc3b98dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3068256880674d0b830bcf9b342a79c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up training loop\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(train_multi_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # remember the batch is size 1 with 1 question and 1 answer\n",
    "        question = batch['question'][0]\n",
    "        question_ids = tokenizer(question, return_tensors='pt')\n",
    "\n",
    "        answer = batch['answers'][0][0]\n",
    "        answer_ids = tokenizer([answer],\n",
    "                               add_special_tokens=False,\n",
    "                               return_attention_mask=False,\n",
    "                               return_token_type_ids=False,\n",
    "                               return_tensors='pt').input_ids\n",
    "        \n",
    "        reader_output, predicted_ans_ids = model(**question_ids.to(device),\n",
    "                                                 answer_ids=answer_ids.to(device),\n",
    "                                                 return_dict=False)\n",
    "        \n",
    "        predicted_answer = tokenizer.decode(predicted_ans_ids)\n",
    "        \n",
    "        # log to tensorboard \n",
    "        writer.add_scalar(\"Reader loss\", reader_output.loss.item())\n",
    "        writer.add_scalar(\"Retriever loss\", reader_output.retriever_loss.item())\n",
    "\n",
    "        for name, weight in model.named_parameters():\n",
    "            if weight.grad is not None:  # and not torch.isnan(weight).all().item():\n",
    "                writer.add_histogram(name, weight, epoch)\n",
    "                writer.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "        \n",
    "        # backward please \n",
    "        reader_output.loss.backward()\n",
    "        \n",
    "        # clip_grad_norm_(model.parameters(), 1.0, norm_type=2.0, error_if_nonfinite=False)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        logging.info(\n",
    "            f\"Epoch: {epoch}, \"\n",
    "            f\"Step: {global_step}, \"\n",
    "            f\"Retriever Loss: {reader_output.retriever_loss.mean()}, \"\n",
    "            f\"Reader Loss: {reader_output.reader_loss.mean()}\\n\"\n",
    "            f\"\\tQuestion: {batch['question'][0]}, Gold Answer: {answer}, Predicted Answer: {predicted_answer}\"\n",
    "        )\n",
    "        \n",
    "        if global_step % checkpoint_interval == 0:\n",
    "            logging.info(f\"Saving checkpint at step {global_step}\")\n",
    "            \n",
    "            model.save_pretrained(f\"checkpoints/short/beam_size_500/checkpoint-{global_step}\")\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step >= num_steps:\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4d002464-df78-43b6-94d5-533c2ae95622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "model.save_pretrained('trained/zsre/v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24233f8c-78e7-432b-9b87-c98777600af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c065631-2402-4381-a1de-de2531e7dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "83b8273e-8a2c-4205-a18e-af03b32c3109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f72675-f278-49eb-9b5d-9fb59e0d6d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1418d8-5fa5-4933-9439-5592cc137112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00f2b00a-5299-4f46-a778-afdeaa851524",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b9385019-3f00-489f-8861-a03cd4af5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from itertools import chain\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e68e13-2742-4388-970c-4ed80f57421d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8724b600-feaa-49e5-b718-dfea68804b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"\n",
    "        Normalize answer. (Copied from ORQA codebase)\n",
    "    \"\"\"\n",
    "    s = unicodedata.normalize(\"NFD\", s)\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "dd07d66c-6f51-46a3-9081-861d09a12c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alan mathison turing'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test normalize ans\n",
    "normalize_answer(\"Alan Mathison Turing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bf14f-a986-441e-a4e7-8429d0c247d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b9427bd4-3bf4-4e75-afed-ad3f9f2ad048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eval_metrics(labels: List, predicted_answer: str, reader_output):\n",
    "    # First, try to find exact match\n",
    "    exact_match = torch.index_select(\n",
    "        torch.index_select(reader_output.reader_correct,\n",
    "                           dim=0,\n",
    "                           index=reader_output.block_idx),\n",
    "        dim=1,\n",
    "        index=reader_output.candidate\n",
    "    )\n",
    "    \n",
    "    def _official_exact_match(predicted_answer, references):\n",
    "        return torch.tensor(\n",
    "            max(\n",
    "                [normalize_answer(predicted_answer) == normalize_answer(reference) for reference in references]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    \n",
    "    official_em = _official_exact_match(predicted_answer, labels)\n",
    "    \n",
    "    eval_metric = dict(\n",
    "        exact_match=exact_match[0][0],\n",
    "        official_exact_match=official_em,\n",
    "        reader_oracle=torch.any(reader_output.reader_correct)\n",
    "    )\n",
    "    \n",
    "    # Get top matches \n",
    "    for k in (5, 10, 50, 100, 500, 1000, 5000):\n",
    "        eval_metric[f\"top_{k}_match\"] = torch.any(reader_output.retriever_correct[:k])\n",
    "        \n",
    "    return eval_metric\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10202332-73c8-4a1f-872a-24b62b5acfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6d9f6530-fd29-4572-b205-58bd4e4f93a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': tensor(False, device='cuda:0'),\n",
       " 'official_exact_match': tensor(False),\n",
       " 'reader_oracle': tensor(False, device='cuda:0'),\n",
       " 'top_5_match': tensor(False, device='cuda:0'),\n",
       " 'top_10_match': tensor(False, device='cuda:0'),\n",
       " 'top_50_match': tensor(False, device='cuda:0'),\n",
       " 'top_100_match': tensor(False, device='cuda:0'),\n",
       " 'top_500_match': tensor(False, device='cuda:0'),\n",
       " 'top_1000_match': tensor(False, device='cuda:0'),\n",
       " 'top_5000_match': tensor(False, device='cuda:0')}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test compute metrics\n",
    "compute_eval_metrics([\"Alan Mathison Turing\"],\n",
    "                     tokenizer.decode(predicted_answer_ids),\n",
    "                     reader_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb4bfbab-6724-4f38-b709-12173819be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set searcher and reader beam size to same values as paper\n",
    "reader_beam_size = 5\n",
    "searcher_beam_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f95945b-b7ac-45af-8513-37002fa080e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8e85a-bbc1-4a8e-94b1-c6b06a06562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b1e11-a6fe-421f-aa81-27fa949cae28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c1e61bdc-2ac0-4fb7-8d1e-ff9b548f32ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all metrics\n",
    "all_metrics = []\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9c51f621-cae7-4fed-823f-b75867dae9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers: [('Antwerp',), ('Toulouse',), ('Saint-Mihiel',), ('Saint-Malo',), ('Saint-Maurice',)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Antwerp', 'Toulouse', 'Saint-Mihiel', 'Saint-Malo', 'Saint-Maurice']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Answers: {batch['answers']}\")\n",
    "\n",
    "list(chain.from_iterable(batch['answers']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "cdeda9b2-7a19-47f8-98d5-ff1d0149be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions for script eval\n",
    "pred_file = open('data/for_eval/model_predictions_2.txt', 'w')\n",
    "ground_truth_file = open('data/for_eval/ground_truth_2.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0268b53f-4cb4-48ac-881b-1cb40246fd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671969b9989644c18bc2d833dedc13ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up eval\n",
    "model.eval()\n",
    "\n",
    "for ebatch in tqdm(eval_multi_dataloader):\n",
    "    question = ebatch['question'][0]\n",
    "    question_ids = tokenizer(question, return_tensors='pt')\n",
    "    \n",
    "    answer = ebatch['answers'][0][0]\n",
    "    answer_ids = tokenizer([answer],\n",
    "    # answer_ids = tokenizer(ebatch['answer'],\n",
    "                           add_special_tokens=False,\n",
    "                           return_attention_mask=False,\n",
    "                           return_token_type_ids=False,\n",
    "                           return_tensors='pt').input_ids\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**question_ids.to(device),\n",
    "                        answer_ids=answer_ids.to(device),\n",
    "                        return_dict=True)\n",
    "\n",
    "    predicted_answer = tokenizer.decode(outputs.predicted_answer_ids)\n",
    "    \n",
    "    all_metrics.append(compute_eval_metrics(list(chain.from_iterable(batch['answers'])),\n",
    "                                            predicted_answer,\n",
    "                                            outputs.reader_output))\n",
    "    \n",
    "    pred_file.write(predicted_answer)\n",
    "    pred_file.write('\\n')\n",
    "    \n",
    "    ground_truth_file.write(answer)  # remember there's multiple answers\n",
    "    ground_truth_file.write('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "de4495cf-6635-42fc-8c11-5b9819fb1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file.close()\n",
    "ground_truth_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2feea69f-742e-493c-9cb1-9d54e1568e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_metrics = {\n",
    "    metric_key: torch.stack((*map(lambda metrics: metrics[metric_key], all_metrics),)) for metric_key in all_metrics[0].keys()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5628f108-23f2-47f1-b311-a64322b110d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Official EM: 0.0\n",
      "Exact Match: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Official EM: {len(((stacked_metrics['official_exact_match'] == True).nonzero(as_tuple=True)[0])) / len(stacked_metrics['official_exact_match']) }\")\n",
    "\n",
    "\n",
    "print(f\"Exact Match: {len(((stacked_metrics['exact_match'] == True).nonzero(as_tuple=True)[0])) / len(stacked_metrics['exact_match'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe3fbc-badf-4278-8b5a-ea23c834cb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1b408e73-611a-4e67-8b30-a1e89ab9131f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/for_eval/ground_truth.txt_2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [250], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     preds \u001b[38;5;241m=\u001b[39m [normalize_answer(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[1;32m      5\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/for_eval/ground_truth.txt_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m      8\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [normalize_answer(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m p]\n\u001b[1;32m      9\u001b[0m p\u001b[38;5;241m.\u001b[39mclose()    \n",
      "File \u001b[0;32m~/retrieval-augmented-models/rvenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/for_eval/ground_truth.txt_2'"
     ]
    }
   ],
   "source": [
    "# Prefer huggingface's evaluate library\n",
    "preds, labels = [], []\n",
    "with open('data/for_eval/model_predictions_2.txt', 'r') as f:\n",
    "    preds = [normalize_answer(line) for line in f]\n",
    "f.close()\n",
    "\n",
    "with open('data/for_eval/ground_truth.txt_2', 'r') as p:\n",
    "    labels = [normalize_answer(line) for line in p]\n",
    "p.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "153acf8d-09d6-4f23-8fa8-3059e455fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5ae176bfc04690af94ff2c1caf6dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.26698071866783524}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set metric to use\n",
    "em_metric = load('exact_match')\n",
    "\n",
    "results = em_metric.compute(predictions=preds, references=labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a9784-77e5-4ac0-ae8a-f8b0fea1f59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395ff80-a460-4f9a-91a0-828968691cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c00d2ff4-67d7-404d-aa63-2076eb484432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56d85cbe-32e8-457a-a34a-41d356630a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27384"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_strings = []\n",
    "\n",
    "for b in eval_dataloader:\n",
    "    answers_strings.append(b['answer'][0])\n",
    "\n",
    "len(answers_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ff480ce-bcf1-4716-aa88-ac08e59f6448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Illinois Institute of Technology', 'Lecanorales', 'defender']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_strings[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbaee2fe-b641-400e-b8c5-0dc15aaf3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_counts = Counter(answers_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9cebe298-fcb5-42ef-93ac-ff5f92b0dce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Antarctica', 478),\n",
       " ('French', 430),\n",
       " ('female', 321),\n",
       " ('midfielder', 188),\n",
       " ('human', 166),\n",
       " ('soprano', 155),\n",
       " ('World War II', 145),\n",
       " ('heart attack', 140),\n",
       " ('male', 137),\n",
       " ('piano', 136)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_counts.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa21ca5-f8ad-4f80-9035-bd27dfa6bfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5d96b-75eb-4ea5-8427-7399d5f4652c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8695ff86-9b34-4444-be8d-98b41cd05985",
   "metadata": {},
   "source": [
    "## Sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc43615b-5741-452c-af24-5f1258114daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answers'],\n",
       "        num_rows: 44499\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answers'],\n",
       "        num_rows: 7983\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2372ef7-35a8-4d21-b553-6fafc81522b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What war did Oscar Veniah Dayton fight in?',\n",
       " 'answers': ['American Civil War',\n",
       "  'World War II',\n",
       "  'Spanish-- American War',\n",
       "  'World War I',\n",
       "  'Korean War']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_dataset['train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f27f7c5-cc6c-4171-a54d-dd046e749134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Adoration of the Trinity by?: \n",
      "\t['Albrecht Drer', 'Giovanni Bellini', 'Vittore Carpi', 'Titian', 'Domenico Rossi']\n",
      "\n",
      "\n",
      "The manufacturer of Colt King Cobra was who?: \n",
      "\t[\"Colt's Manufacturing Company\", \"Stuart's Manufacturing Company\", \"Colt's Manufacturing\", \"Colt's Arms\", \"Colt's Manufacturing Corporation\"]\n",
      "\n",
      "\n",
      "Who is South Park by?: \n",
      "\t['Trey Parker', 'Matt Pond PA', 'Matt Bish', 'Matt Lucas', 'Matt Groening', 'Matt Stone']\n",
      "\n",
      "\n",
      "What was Harvey R. Miller's occupation?: \n",
      "\t['lawyer', 'politician', 'screenwriter', 'judge', 'architect']\n",
      "\n",
      "\n",
      "What country is Miguel Covarrubias from?: \n",
      "\t['Mexico', 'Argentina', 'Cuba', 'Colombia']\n",
      "\n",
      "\n",
      "Which was the record label for Short Dog's in the House?: \n",
      "\t['Jive Records', 'Arista Records', 'Atlantic Records', 'Motown']\n",
      "\n",
      "\n",
      "Which network is If Katie Hopkins Ruled the World a part of?: \n",
      "\t['TLC', 'BBC Two', 'BBC One', 'ESPN', 'Disney Channel']\n",
      "\n",
      "\n",
      "Under whose direction was Maula Jatt 2 produced?: \n",
      "\t['Bilal Lashari', 'Maula Jatt', 'M Maula Jatt', 'Raj Kapoor', 'Rajkumar Hirani']\n",
      "\n",
      "\n",
      "Who was responsible for the direction of The Girl Who Returned?: \n",
      "\t['Lloyd Kaufman', 'Lloyd Nolan', 'Lloyd Bacon', 'Tinto Brass', 'Lloyd Ingraham']\n",
      "\n",
      "\n",
      "Who designed House for an Art Lover?: \n",
      "\t['Charles Rennie Mackintosh', 'Charles T Lyons', 'Charles Girault', 'Charles Barry', 'Charles Holl']\n",
      "\n",
      "\n",
      "What war did Oscar Veniah Dayton fight in?: \n",
      "\t['American Civil War', 'World War II', 'Spanish-- American War', 'World War I', 'Korean War']\n",
      "\n",
      "\n",
      "Who gives out the Prix Wilder-Penfield award?: \n",
      "\t['Government of Quebec', 'Institute of Physics', 'Gaston', 'Granada Foundation', 'Government of France']\n",
      "\n",
      "\n",
      "What instrument is Variations srieuses for?: \n",
      "\t['piano', 'orchestra', 'violin', 'flute']\n",
      "\n",
      "\n",
      "What was Diane Sands's occupation?: \n",
      "\t['politician', 'journalist', 'singer', 'writer', 'ice hockey player']\n",
      "\n",
      "\n",
      "What is the name of the place where Yr Amserau can be found?: \n",
      "\t['Welsh Newspapers Online', 'National Gallery of Art', 'British Museum', 'National Library of Wales', 'Metropolitan Museum of Art']\n",
      "\n",
      "\n",
      "Which series is Wilson's Heart a part of?: \n",
      "\t['House', \"Dad's Army\", 'Futurama', 'Gideon Fell', 'Desperate Housewives']\n",
      "\n",
      "\n",
      "In which year Southern Qi ceased to exist?: \n",
      "\t['502', '581', '394', '550', '376']\n",
      "\n",
      "\n",
      "The Maigret and the Burglar's Wife has what character?: \n",
      "\t['Jules Maigret', 'Agrippa the Younger', 'Agatha Christie', 'Agrippina the Younger', 'Sherlock Holmes']\n",
      "\n",
      "\n",
      "What kind of  occupation does Karim-Mohamed Maamoun have?: \n",
      "\t['tennis player', 'cricketer', 'writer', 'poet', 'architect']\n",
      "\n",
      "\n",
      "Which country's citizen was Nico Vivarelli?: \n",
      "\t['Italy', 'New Zealand', 'Switzerland', 'France', 'Sweden']\n",
      "\n",
      "\n",
      "Who is the Virgo Supercluster named after?: \n",
      "\t['Virgo Cluster', 'Virgo Borealis', 'Scorpius', 'Ophiuchus']\n",
      "\n",
      "\n",
      "What is the full date that 2015 Bahrain Grand Prix crashed on?: \n",
      "\t['19 April 2015']\n",
      "\n",
      "\n",
      "What is the continent of Mhire Spur?: \n",
      "\t['Antarctica']\n",
      "\n",
      "\n",
      "What was the station that aired Animal Precinct?: \n",
      "\t['Animal Planet', 'Seven Network', 'NBC', 'Animal Network', 'CBS']\n",
      "\n",
      "\n",
      "Which family is Acantuerta a part of?: \n",
      "\t['Noctuidae', 'Geometridae', 'Crambidae', 'Tineidae']\n",
      "\n",
      "\n",
      "Who made 1921 Pala known?: \n",
      "\t['Tom Gehrels', 'August Kopff', 'Pablo Cottenot', 'Alfred Pala', 'Sylvester I']\n",
      "\n",
      "\n",
      "What sports team was Stanislav Romanov a member of?: \n",
      "\t['HC Lada Togliatti', 'FC Shakhtar Donetsk', 'Spartak Myjava', 'Spartak Mykolaiv']\n",
      "\n",
      "\n",
      "Which city was the birthplace of Emily Shanks?: \n",
      "\t['Moscow', 'New Jersey', 'New Orleans', 'Philadelphia', 'Chicago']\n",
      "\n",
      "\n",
      "The main director of The Miracle of Bern was who?: \n",
      "\t['Snke Wortmann', 'Johannes Vermeer', 'Gustav Ucicky', 'Johannes Guter', 'Rudolf Platte']\n",
      "\n",
      "\n",
      "Under whose direction was Visit to a Chief's Son produced?: \n",
      "\t['Lamont Johnson', 'Gianfranco Baldanello', 'Giorgio Bianchi', 'Maurice Elvey', 'Rudolf Platte']\n",
      "\n",
      "\n",
      "Which is the position of Jules Basile Onambele?: \n",
      "\t['midfielder', 'defender', 'forward', 'goalkeeper', 'winger']\n",
      "\n",
      "\n",
      "What is Raymond Brown Hesselyn's country of original?: \n",
      "\t['New Zealand', 'Canada', 'Australia', 'France', 'United Kingdom']\n",
      "\n",
      "\n",
      "In which year was Who's Afraid of Red, Yellow and Blue incepted?: \n",
      "\t['1966', '2006', '1994', '2005', '1930']\n",
      "\n",
      "\n",
      "What was the name of Connor Tobin's team?: \n",
      "\t['Carolina RailHawks', 'Winnipeg Jets', 'Tampa Bay Lightning', 'St Louis Cardinals', 'Edmonton Oilers']\n",
      "\n",
      "\n",
      "Who created Parnaso Espaol?: \n",
      "\t['Juan Jos Lpez de Sedano', 'Juan Luis Guerra', 'Juan Manuel Snchez Gordillo', 'Juan Carlos Lpez de Sedano', 'Juan Luna']\n",
      "\n",
      "\n",
      "Which artist is Petitioning the Empty Sky co-written and recorded by?: \n",
      "\t['Converge', 'Cantalize', 'Lionel Richie', 'Fabolous', 'Fantasio']\n",
      "\n",
      "\n",
      "Which city was the birthplace of Raimondo Van Riel?: \n",
      "\t['Rome', 'Rio de Janeiro', 'Milan', 'Bologna', 'Brescia']\n",
      "\n",
      "\n",
      "Who published Potomac Review?: \n",
      "\t['Montgomery College', 'Washington & Jefferson College', 'Ohio State University', 'West Virginia University', 'Potomac College']\n",
      "\n",
      "\n",
      "Which is the date of death for Abraham Acton?: \n",
      "\t['16 May 1915', '1780', '1828', '1825', '1818']\n",
      "\n",
      "\n",
      "Which is the league of Iowa Cubs?: \n",
      "\t['Pacific Coast League', 'International League', 'National Premier Soccer League', 'National Premier Baseball League', 'National Premier League']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 40\n",
    "\n",
    "for dict_obj in multi_dataset['train']:\n",
    "    if count < 1:\n",
    "        break\n",
    "    # list(dict.fromkeys(...)) to maintain order of the \n",
    "    print(f\"{dict_obj['question']}: \\n\\t{list(dict.fromkeys(dict_obj['answers']))}\")\n",
    "    print('\\n')\n",
    "    \n",
    "    count -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620f612-3b04-4f25-bf9a-277aae636586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945cc336-848d-4420-ad11-a61509caf003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
